{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import pydot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "//anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import pickle \n",
    "import scipy\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "import re\n",
    "import gensim.models.word2vec\n",
    "import gensim.models.word2vec as w2v\n",
    "np.random.seed(13)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, GRU, Input, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data_label.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   labels = pickle.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OUR DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,labels, test_size=.3,\n",
    "                                                  random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644486, 276209)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644486, 276209)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644486, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276209, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, len(set(labels)))\n",
    "y_test = np_utils.to_categorical(y_test, len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((644486, 5), (276209, 5))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, input_shape=(10, 64))`\n"
     ]
    }
   ],
   "source": [
    "## The words are embedded and passed into a convolutional layer , whose outputs are passed into LSTM \n",
    "## We can optimize by trying different parameters \n",
    "#embedding_vector_length = 16\n",
    "model = Sequential()\n",
    "model.add(Embedding(100, embedding_vector_length))\n",
    "model.add(Convolution1D(filters=8, kernel_size=5, padding='same', activation='relu',input_shape=(5,1)))\n",
    "model.add(Convolution1D(filters=4, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(Convolution1D(filters=2, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 5, 8)              48        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5, 4)              132       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5, 2)              26        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 2, 64)             17152     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 29,939.0\n",
      "Trainable params: 29,939.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 451140 samples, validate on 193346 samples\n",
      "Epoch 1/10\n",
      "451140/451140 [==============================] - 93s - loss: 1.0034 - acc: 0.5849 - val_loss: 0.9527 - val_acc: 0.6056\n",
      "Epoch 2/10\n",
      "451140/451140 [==============================] - 106s - loss: 0.9345 - acc: 0.6151 - val_loss: 0.9043 - val_acc: 0.6284\n",
      "Epoch 3/10\n",
      "451140/451140 [==============================] - 93s - loss: 0.8991 - acc: 0.6291 - val_loss: 0.8897 - val_acc: 0.6321\n",
      "Epoch 4/10\n",
      "451140/451140 [==============================] - 93s - loss: 0.8766 - acc: 0.6377 - val_loss: 0.8820 - val_acc: 0.6352\n",
      "Epoch 5/10\n",
      "451140/451140 [==============================] - 97s - loss: 0.8622 - acc: 0.6431 - val_loss: 0.8597 - val_acc: 0.6430\n",
      "Epoch 6/10\n",
      "451140/451140 [==============================] - 95s - loss: 0.8504 - acc: 0.6467 - val_loss: 0.8314 - val_acc: 0.6538\n",
      "Epoch 7/10\n",
      "451140/451140 [==============================] - 97s - loss: 0.8416 - acc: 0.6506 - val_loss: 0.8253 - val_acc: 0.6556\n",
      "Epoch 8/10\n",
      "451140/451140 [==============================] - 96s - loss: 0.8318 - acc: 0.6542 - val_loss: 0.8255 - val_acc: 0.6533\n",
      "Epoch 9/10\n",
      "451140/451140 [==============================] - 96s - loss: 0.8256 - acc: 0.6564 - val_loss: 0.8078 - val_acc: 0.6620\n",
      "Epoch 10/10\n",
      "451140/451140 [==============================] - 103s - loss: 0.8186 - acc: 0.6600 - val_loss: 0.8104 - val_acc: 0.6635\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.reshape(X_train.shape[0],X_train.shape[1],1), y_train,\n",
    "                    epochs=10, batch_size=128,\n",
    "                    verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276209, 5)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(X_test).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276209/276209 [==============================] - 16s    \n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test.reshape(X_test.shape[0],X_test.shape[1],1), y_test,\n",
    "                       batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.814912068212\n",
      "Test accuracy: 0.6629363996\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted_arr = model.predict(X_test.reshape(X_test.shape[0],X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276209, 5, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.reshape(X_test.shape[0],X_test.shape[1],1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = []\n",
    "for i in y_test:\n",
    "    Y_test.append(np.where(i == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276209"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66293639961\n",
      "0.657948555193\n",
      "0.660131336777\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(Y_test, y_predicted, average='weighted'))\n",
    "print(precision_score(Y_test, y_predicted, average='weighted'))\n",
    "print(f1_score(Y_test, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>reviews(3)</th>\n",
       "      <th>title(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23766</td>\n",
       "      <td>7195</td>\n",
       "      <td>971</td>\n",
       "      <td>14861</td>\n",
       "      <td>5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5906</td>\n",
       "      <td>35978</td>\n",
       "      <td>816</td>\n",
       "      <td>5059</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>152</td>\n",
       "      <td>53746</td>\n",
       "      <td>483</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13984</td>\n",
       "      <td>4482</td>\n",
       "      <td>2079</td>\n",
       "      <td>31944</td>\n",
       "      <td>6189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6059</td>\n",
       "      <td>4512</td>\n",
       "      <td>1148</td>\n",
       "      <td>6362</td>\n",
       "      <td>37675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  reviews(3)  title(4)\n",
       "0           23766            7195          971       14861      5664\n",
       "1            5906           35978          816        5059      6488\n",
       "2              53             152        53746         483       637\n",
       "3           13984            4482         2079       31944      6189\n",
       "4            6059            4512         1148        6362     37675"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(Y_test,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','reviews(3)','title(4)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('cnn-lstm-final.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "synthetic_data = ['Cook the rigatoni according to the package instructions. When there is just a few minutes left of cooking, add the baby broccolini and cook till fork-tender. Remove, drain, and set aside.','Preheat oven to 350 degrees F (175 degrees C)',' 1/2 (12 ounce) package uncooked lasagna noodles','Calories:324 kcal','This receipe exceded my expectations. I took','2 tablespoons milk','2 cups shredded mozzarella cheese, divided','This is my FAVORITE recipe in the world!','Wow! I just finished baking this lasagna','I love tofu, and I love lasagna ... I never','This was very bland. I did add more tomato','Fat: 14.5 g','Carbs: 26.2g','Protein: 24.1 g','Cholesterol: 81 mg','In a medium bowl combine tofu, eggs, salt, pep','Layer lasagna noodles with the sauce mixture','Bake in preheated oven for 25 to 35 minutes.','2 cups shredded mozzarella cheese, divided','1/2 cup grated Parmesan cheese','2 cups shredded mozzarella cheese, divided','1/4 teaspoon ground nutmeg']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2 tablespoons milk'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_data[5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(LSTM(64,return_sequences=True,input_shape=(5,1)))\n",
    "model1.add(LSTM(32, return_sequences=True))\n",
    "model1.add(LSTM(9))\n",
    "model1.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 5, 64)             16896     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 5, 32)             12416     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 9)                 1512      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 50        \n",
      "=================================================================\n",
      "Total params: 30,874.0\n",
      "Trainable params: 30,874\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 451140 samples, validate on 193346 samples\n",
      "Epoch 1/5\n",
      "451140/451140 [==============================] - 307s - loss: 0.7113 - acc: 0.7054 - val_loss: 0.6323 - val_acc: 0.7387\n",
      "Epoch 2/5\n",
      "451140/451140 [==============================] - 293s - loss: 0.5969 - acc: 0.7597 - val_loss: 0.5679 - val_acc: 0.7730\n",
      "Epoch 3/5\n",
      "451140/451140 [==============================] - 220s - loss: 0.5628 - acc: 0.7771 - val_loss: 0.5477 - val_acc: 0.7827\n",
      "Epoch 4/5\n",
      "451140/451140 [==============================] - 221s - loss: 0.5405 - acc: 0.7873 - val_loss: 0.5304 - val_acc: 0.7902\n",
      "Epoch 5/5\n",
      "451140/451140 [==============================] - 221s - loss: 0.5271 - acc: 0.7930 - val_loss: 0.5233 - val_acc: 0.7950\n"
     ]
    }
   ],
   "source": [
    "history = model1.fit(X_train.reshape(X_train.shape[0],X_train.shape[1],1), y_train,\n",
    "                    epochs=5, batch_size=128,\n",
    "                    verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276096/276209 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test.reshape(X_test.shape[0],X_test.shape[1],1), y_test,\n",
    "                       batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.523923744019\n",
      "Test accuracy: 0.793967611471\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted_arr = model1.predict(X_test.reshape(X_test.shape[0],X_test.shape[1],1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = []\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = []\n",
    "for i in y_test:\n",
    "    Y_test.append(np.where(i == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793967611483\n",
      "0.790369155034\n",
      "0.791153926735\n"
     ]
    }
   ],
   "source": [
    "print(recall_score(Y_test, y_predicted, average='weighted'))\n",
    "print(precision_score(Y_test, y_predicted, average='weighted'))\n",
    "print(f1_score(Y_test, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>reviews(3)</th>\n",
       "      <th>title(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29296</td>\n",
       "      <td>5886</td>\n",
       "      <td>100</td>\n",
       "      <td>11907</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3294</td>\n",
       "      <td>44369</td>\n",
       "      <td>165</td>\n",
       "      <td>2204</td>\n",
       "      <td>4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>130</td>\n",
       "      <td>54921</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8139</td>\n",
       "      <td>3136</td>\n",
       "      <td>108</td>\n",
       "      <td>44466</td>\n",
       "      <td>2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3736</td>\n",
       "      <td>2937</td>\n",
       "      <td>317</td>\n",
       "      <td>2517</td>\n",
       "      <td>46249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  reviews(3)  title(4)\n",
       "0           29296            5886          100       11907      5268\n",
       "1            3294           44369          165        2204      4215\n",
       "2              10             130        54921           7         3\n",
       "3            8139            3136          108       44466      2829\n",
       "4            3736            2937          317        2517     46249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(metrics.confusion_matrix(Y_test,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','reviews(3)','title(4)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model1.save('lstm-final.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
