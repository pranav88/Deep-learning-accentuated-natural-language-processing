{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import pydot\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "from keras.models import load_model\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/lib/python3.5/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n",
      "Using TensorFlow backend.\n",
      "//anaconda/lib/python3.5/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import pickle \n",
    "import scipy\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "import re\n",
    "import gensim.models.word2vec\n",
    "import gensim.models.word2vec as w2v\n",
    "np.random.seed(13)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, GRU, Input, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.utils import plot_model\n",
    "%matplotlib inline\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data.txt\", \"rb\") as fp:   # Unpickling the data we obtained from big query\n",
    "...   data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data_label.txt\", \"rb\") as fp:   # Unpickling the data we obtained from big query\n",
    "...   labels = pickle.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN-LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data,labels, test_size=.3,\n",
    "                                                  random_state=5) ## test train split using sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "maxlen = 5 ## length of sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## tokenize and convert the texts to sequence and pad them\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train = tokenizer.texts_to_sequences(X_train)\n",
    "X_train = sequence.pad_sequences(X_train, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## do the same as bove with the test data\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X_test)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "X_test = sequence.pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(644486, 5)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276209, 5)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## one hot encoding of our labels\n",
    "y_train = np_utils.to_categorical(y_train, len(set(labels)))\n",
    "y_test = np_utils.to_categorical(y_test, len(set(labels)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((644486, 5), (276209, 5))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "//anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:10: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(64, return_sequences=True, input_shape=(10, 64))`\n"
     ]
    }
   ],
   "source": [
    "## The words are embedded and passed into a convolutional layer , whose outputs are passed into LSTM \n",
    "## We can optimize by trying different parameters \n",
    "#embedding_vector_length = 16\n",
    "model = Sequential()\n",
    "model.add(Embedding(100, embedding_vector_length))\n",
    "model.add(Convolution1D(filters=8, kernel_size=5, padding='same', activation='relu',input_shape=(5,1)))\n",
    "model.add(Convolution1D(filters=4, kernel_size=4, padding='same', activation='relu'))\n",
    "model.add(Convolution1D(filters=2, kernel_size=3, padding='same', activation='relu'))\n",
    "model.add(MaxPooling1D(pool_size=2))\n",
    "model.add(LSTM(64, input_dim=64, input_length=10, return_sequences=True))\n",
    "model.add(LSTM(32, return_sequences=False))\n",
    "model.add(Dense(5, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 5, 8)              48        \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 5, 4)              132       \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 5, 2)              26        \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 2, 2)              0         \n",
      "_________________________________________________________________\n",
      "lstm_5 (LSTM)                (None, 2, 64)             17152     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 5)                 165       \n",
      "=================================================================\n",
      "Total params: 29,939.0\n",
      "Trainable params: 29,939.0\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 451140 samples, validate on 193346 samples\n",
      "Epoch 1/10\n",
      "451140/451140 [==============================] - 93s - loss: 1.0034 - acc: 0.5849 - val_loss: 0.9527 - val_acc: 0.6056\n",
      "Epoch 2/10\n",
      "451140/451140 [==============================] - 106s - loss: 0.9345 - acc: 0.6151 - val_loss: 0.9043 - val_acc: 0.6284\n",
      "Epoch 3/10\n",
      "451140/451140 [==============================] - 93s - loss: 0.8991 - acc: 0.6291 - val_loss: 0.8897 - val_acc: 0.6321\n",
      "Epoch 4/10\n",
      "451140/451140 [==============================] - 93s - loss: 0.8766 - acc: 0.6377 - val_loss: 0.8820 - val_acc: 0.6352\n",
      "Epoch 5/10\n",
      "451140/451140 [==============================] - 97s - loss: 0.8622 - acc: 0.6431 - val_loss: 0.8597 - val_acc: 0.6430\n",
      "Epoch 6/10\n",
      "451140/451140 [==============================] - 95s - loss: 0.8504 - acc: 0.6467 - val_loss: 0.8314 - val_acc: 0.6538\n",
      "Epoch 7/10\n",
      "451140/451140 [==============================] - 97s - loss: 0.8416 - acc: 0.6506 - val_loss: 0.8253 - val_acc: 0.6556\n",
      "Epoch 8/10\n",
      "451140/451140 [==============================] - 96s - loss: 0.8318 - acc: 0.6542 - val_loss: 0.8255 - val_acc: 0.6533\n",
      "Epoch 9/10\n",
      "451140/451140 [==============================] - 96s - loss: 0.8256 - acc: 0.6564 - val_loss: 0.8078 - val_acc: 0.6620\n",
      "Epoch 10/10\n",
      "451140/451140 [==============================] - 103s - loss: 0.8186 - acc: 0.6600 - val_loss: 0.8104 - val_acc: 0.6635\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train.reshape(X_train.shape[0],X_train.shape[1],1), y_train,\n",
    "                    epochs=10, batch_size=128,\n",
    "                    verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276209/276209 [==============================] - 16s    \n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test.reshape(X_test.shape[0],X_test.shape[1],1), y_test,\n",
    "                       batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.814912068212\n",
      "Test accuracy: 0.6629363996\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted_arr = model.predict(X_test.reshape(X_test.shape[0],X_test.shape[1],1)) ## predictions on established model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(276209, 5, 1)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.reshape(X_test.shape[0],X_test.shape[1],1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = []      ## get the classes from the predictions\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = [] ## convert back to original labels\n",
    "for i in y_test:\n",
    "    Y_test.append(np.where(i == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.66293639961\n",
      "0.657948555193\n",
      "0.660131336777\n"
     ]
    }
   ],
   "source": [
    "## calculate recall , precision and f1\n",
    "print(recall_score(Y_test, y_predicted, average='weighted'))\n",
    "print(precision_score(Y_test, y_predicted, average='weighted'))\n",
    "print(f1_score(Y_test, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>reviews(3)</th>\n",
       "      <th>title(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23766</td>\n",
       "      <td>7195</td>\n",
       "      <td>971</td>\n",
       "      <td>14861</td>\n",
       "      <td>5664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5906</td>\n",
       "      <td>35978</td>\n",
       "      <td>816</td>\n",
       "      <td>5059</td>\n",
       "      <td>6488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>152</td>\n",
       "      <td>53746</td>\n",
       "      <td>483</td>\n",
       "      <td>637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13984</td>\n",
       "      <td>4482</td>\n",
       "      <td>2079</td>\n",
       "      <td>31944</td>\n",
       "      <td>6189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6059</td>\n",
       "      <td>4512</td>\n",
       "      <td>1148</td>\n",
       "      <td>6362</td>\n",
       "      <td>37675</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  reviews(3)  title(4)\n",
       "0           23766            7195          971       14861      5664\n",
       "1            5906           35978          816        5059      6488\n",
       "2              53             152        53746         483       637\n",
       "3           13984            4482         2079       31944      6189\n",
       "4            6059            4512         1148        6362     37675"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confusion matrix to see the predictions we got right\n",
    "pd.DataFrame(metrics.confusion_matrix(Y_test,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','reviews(3)','title(4)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save the model\n",
    "model.save('cnn-lstm-final.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## define lstm , return sequences returns the entire sequence\n",
    "model1 = Sequential()\n",
    "model1.add(LSTM(64,return_sequences=True,input_shape=(5,1)))\n",
    "model1.add(LSTM(32, return_sequences=True))\n",
    "model1.add(LSTM(9))\n",
    "model1.add(Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_10 (LSTM)               (None, 5, 64)             16896     \n",
      "_________________________________________________________________\n",
      "lstm_11 (LSTM)               (None, 5, 32)             12416     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 9)                 1512      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 5)                 50        \n",
      "=================================================================\n",
      "Total params: 30,874.0\n",
      "Trainable params: 30,874\n",
      "Non-trainable params: 0.0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "## compile the model , with categorical cross entropy and adam\n",
    "model1.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])\n",
    "print(model1.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 451140 samples, validate on 193346 samples\n",
      "Epoch 1/5\n",
      "451140/451140 [==============================] - 307s - loss: 0.7113 - acc: 0.7054 - val_loss: 0.6323 - val_acc: 0.7387\n",
      "Epoch 2/5\n",
      "451140/451140 [==============================] - 293s - loss: 0.5969 - acc: 0.7597 - val_loss: 0.5679 - val_acc: 0.7730\n",
      "Epoch 3/5\n",
      "451140/451140 [==============================] - 220s - loss: 0.5628 - acc: 0.7771 - val_loss: 0.5477 - val_acc: 0.7827\n",
      "Epoch 4/5\n",
      "451140/451140 [==============================] - 221s - loss: 0.5405 - acc: 0.7873 - val_loss: 0.5304 - val_acc: 0.7902\n",
      "Epoch 5/5\n",
      "451140/451140 [==============================] - 221s - loss: 0.5271 - acc: 0.7930 - val_loss: 0.5233 - val_acc: 0.7950\n"
     ]
    }
   ],
   "source": [
    "## fit the model over 5 epochs and standard batch size\n",
    "history = model1.fit(X_train.reshape(X_train.shape[0],X_train.shape[1],1), y_train,\n",
    "                    epochs=5, batch_size=128,\n",
    "                    verbose=1, validation_split=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "276096/276209 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "score = model1.evaluate(X_test.reshape(X_test.shape[0],X_test.shape[1],1), y_test,\n",
    "                       batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.523923744019\n",
      "Test accuracy: 0.793967611471\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_predicted_arr = model1.predict(X_test.reshape(X_test.shape[0],X_test.shape[1],1)) ## predicted values from model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_predicted = [] ## predicted classes\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_test = [] ## convert back to original labels\n",
    "for i in y_test:\n",
    "    Y_test.append(np.where(i == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.793967611483\n",
      "0.790369155034\n",
      "0.791153926735\n"
     ]
    }
   ],
   "source": [
    "## calcuate recall precision and f1\n",
    "print(recall_score(Y_test, y_predicted, average='weighted'))\n",
    "print(precision_score(Y_test, y_predicted, average='weighted'))\n",
    "print(f1_score(Y_test, y_predicted, average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>reviews(3)</th>\n",
       "      <th>title(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29296</td>\n",
       "      <td>5886</td>\n",
       "      <td>100</td>\n",
       "      <td>11907</td>\n",
       "      <td>5268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3294</td>\n",
       "      <td>44369</td>\n",
       "      <td>165</td>\n",
       "      <td>2204</td>\n",
       "      <td>4215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>130</td>\n",
       "      <td>54921</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8139</td>\n",
       "      <td>3136</td>\n",
       "      <td>108</td>\n",
       "      <td>44466</td>\n",
       "      <td>2829</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3736</td>\n",
       "      <td>2937</td>\n",
       "      <td>317</td>\n",
       "      <td>2517</td>\n",
       "      <td>46249</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  reviews(3)  title(4)\n",
       "0           29296            5886          100       11907      5268\n",
       "1            3294           44369          165        2204      4215\n",
       "2              10             130        54921           7         3\n",
       "3            8139            3136          108       44466      2829\n",
       "4            3736            2937          317        2517     46249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## confusion matrix to see the predictions we got right\n",
    "pd.DataFrame(metrics.confusion_matrix(Y_test,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','reviews(3)','title(4)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save the model as a h5 file\n",
    "model1.save('lstm-final.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
