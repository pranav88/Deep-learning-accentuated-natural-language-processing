{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from IPython.display import SVG\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "import pydot\n",
    "from keras.utils import plot_model\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from gensim.models.doc2vec import LabeledSentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import pickle\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py27/lib/python2.7/site-packages/IPython/html.py:14: ShimWarning: The `IPython.html` package has been deprecated. You should import from `notebook` instead. `IPython.html.widgets` has moved to `ipywidgets`.\n",
      "  \"`IPython.html.widgets` has moved to `ipywidgets`.\", ShimWarning)\n",
      "//anaconda/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "//anaconda/envs/py27/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import pickle \n",
    "import scipy\n",
    "from keras.datasets import reuters\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "import gensim\n",
    "import pickle\n",
    "from gensim.models.doc2vec import LabeledSentence\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "import re\n",
    "import gensim.models.word2vec\n",
    "import gensim.models.word2vec as w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data_label.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   labels = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocabulary_size = len(data)\n",
    "embedding_size = 200\n",
    "batch_size=128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "source": [
    "## Word2vec tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get the words from the sentences , tokenizing\n",
    "def sentence_to_wordlist(raw):\n",
    "    clean = re.sub(\"[^a-zA-Z]\",\" \", raw) ## regular expression to get the words\n",
    "    words = clean.split()\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for raw_sentence in data: ## get the sentences from our data and tokenize them using the function predefined\n",
    "    if len(raw_sentence) > 0:\n",
    "        sentences.append(sentence_to_wordlist(raw_sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bake for 10-12 minutes until cooked through and golden brown.\n",
      "[u'Bake', u'for', u'minutes', u'until', u'cooked', u'through', u'and', u'golden', u'brown']\n"
     ]
    }
   ],
   "source": [
    "print(data[5])\n",
    "print(sentence_to_wordlist(data[5])) ## having a look at the words of the given sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data contains 13,760,054 tokens\n"
     ]
    }
   ],
   "source": [
    "## get the total number of tokens in our dataset\n",
    "token_count = sum([len(sentence) for sentence in sentences])\n",
    "print(\"data contains {0:,} tokens\".format(token_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_features = 200\n",
    "\n",
    "# Minimum word count threshold.\n",
    "min_word_count = 1\n",
    "\n",
    "# Number of threads to run in parallel.\n",
    "num_workers = multiprocessing.cpu_count()\n",
    "\n",
    "# Context window length.\n",
    "context_size = 7\n",
    "\n",
    "# Downsample setting for frequent words.\n",
    "#rate 0 and 1e-5 \n",
    "#how often to use\n",
    "downsampling = 1e-3\n",
    "\n",
    "# Seed for the RNG, to make the results reproducible.\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## specify  the parameters for the word2vec model created using gensim\n",
    "food2vec = w2v.Word2Vec(\n",
    "    sg=1,\n",
    "    seed=seed,\n",
    "    workers=num_workers,\n",
    "    size=num_features,\n",
    "    min_count=min_word_count,\n",
    "    window=context_size,\n",
    "    sample=downsampling\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## build the vocabulary\n",
    "food2vec.build_vocab(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89026\n"
     ]
    }
   ],
   "source": [
    "## Total vectors after we repreent the words in our data as vectors\n",
    "num_w2v = len(food2vec.wv.index2word)\n",
    "print (num_w2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/pranavakaarthikprabhakaran/Desktop/capstone-project\r\n"
     ]
    }
   ],
   "source": [
    "## current working directory\n",
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = \"WORDS/word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## We created a matrix of zeroes for the specified dimension \n",
    "w2v = np.zeros((num_w2v,200))\n",
    "with open(\"WORDS/metadata.tsv\", 'w+') as file_metadata: ## Tensorboard requires that we store labels as a tsv file\n",
    "    for i,word in enumerate(food2vec.wv.index2word): ## get the word and the vector that reprsents the word\n",
    "        w2v[i] = food2vec[word]\n",
    "        file_metadata.write(word + '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89026, 200)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v.shape ## asserting the shape of our word2vec matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#FOLDER = \"WORDS/word2vec\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Here we pass the vectors we created into tensors to visalise them\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "\n",
    "\n",
    "# setup a TensorFlow session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = tf.Variable([0.0], name='embedding')\n",
    "place = tf.placeholder(tf.float32, shape=[None, 200])\n",
    "set_x = tf.assign(X, place, validate_shape=False)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(set_x, feed_dict={place: w2v})\n",
    "\n",
    "# create a TensorFlow summary writer\n",
    "#summary_writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "summary_writer = tf.summary.FileWriter(FOLDER,sess.graph)\n",
    "\n",
    "# Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "\n",
    "embedding_conf = config.embeddings.add()\n",
    "# Link the tensor to its metadata file (e.g. labels).\n",
    "embedding_conf.tensor_name = 'embedding:0'\n",
    "embedding_conf.metadata_path = FOLDER +'/metadata.tsv' \n",
    "\n",
    "# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "# read this file during startup.\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "# save the model\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, FOLDER + 'model.ckpt')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-a9c60156d637>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'metadata.tsv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwritelines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "with open('metadata.tsv', 'w') as file:\n",
    "    file.writelines(df.to_csv(sep='\\t',index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Doc2vec Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"doc2vec_data.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"doc2vec_label.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   labels = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "docs = LabeledSentence(words=data,tags=labels) #documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class LabeledLineSentence(object):\n",
    "    def __init__(self, doc_list, labels_list):\n",
    "        self.labels_list = labels_list\n",
    "        self.doc_list = doc_list\n",
    "    def __iter__(self):\n",
    "        for idx, doc in enumerate(self.doc_list):\n",
    "            yield LabeledSentence(words=doc.split(),tags=[self.labels_list[idx]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "it = LabeledLineSentence(data, labels)\n",
    "words = []\n",
    "for i in it:\n",
    "    #j = j+1\n",
    "    words.append(i[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Doc2Vec(size=10, window=10, min_count=5, workers=40,alpha=0.025, min_alpha=0.025)\n",
    "model.build_vocab(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for epoch in range(3):\n",
    "    model.train(it,total_examples=model.corpus_count,epochs=model.iter)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha # fix the learning rate, no deca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('capstone.doc2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc_vecs = [model.infer_vector(words[i]) for i in range(0,len(words))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#dist = 1 - cosine_similarity(doc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#len(dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Doc2vec Tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert our labels represented as numbers to names\n",
    "labels_names1 = []\n",
    "for i in labels:\n",
    "    if i == 0:\n",
    "        labels_names1.append('preparation')\n",
    "    elif i == 1:\n",
    "        labels_names1.append('ingredients')\n",
    "    elif i == 2:\n",
    "        labels_names1.append('nutrient')\n",
    "    elif i == 3:\n",
    "        labels_names1.append('reviews')\n",
    "    else:\n",
    "        labels_names1.append('title')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## provide colors for each of the labels\n",
    "labels_names = []\n",
    "for i in labels:\n",
    "    if i == 0:\n",
    "        labels_names.append('red')\n",
    "    elif i == 1:\n",
    "        labels_names.append('green')\n",
    "    elif i == 2:\n",
    "        labels_names.append('blue')\n",
    "    elif i == 3:\n",
    "        labels_names.append('pink')\n",
    "    else:\n",
    "        labels_names.append('black')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Convert the doc2vec array to a 2d matrix\n",
    "d2v = np.array(doc_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17914, 10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the shape\n",
    "d2v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## make a directory to store the checkpoints\n",
    "!mkdir doc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FOLDER = 'doc2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create pandas dataframe of labels and their names\n",
    "df1=pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df1['labels']=labels_names1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df1['colors']=labels_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Alternative way to write the tsv metadata file\n",
    "#with open(FOLDER + \"/metadata.tsv\", 'w+') as file_metadata:\n",
    "    #for i in labels_names1:\n",
    "        #file_metadata.write(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create our metadata tsv file to store the labels \n",
    "with open(FOLDER + '/metadata.tsv', 'w') as file:\n",
    "    file.writelines(df1.to_csv(sep='\\t',index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "import numpy as np\n",
    "\n",
    "# setup a TensorFlow session\n",
    "tf.reset_default_graph()\n",
    "sess = tf.InteractiveSession()\n",
    "\n",
    "X = tf.Variable([0.0], name='embedding')\n",
    "place = tf.placeholder(tf.float32, shape=[None, 10])\n",
    "set_x = tf.assign(X, place, validate_shape=False)\n",
    "\n",
    "sess.run(tf.global_variables_initializer())\n",
    "sess.run(set_x, feed_dict={place: d2v})\n",
    "\n",
    "# create a TensorFlow summary writer\n",
    "#summary_writer = tf.summary.FileWriter('logs', sess.graph)\n",
    "summary_writer = tf.summary.FileWriter(FOLDER,sess.graph)\n",
    "\n",
    "# Format: tensorflow/contrib/tensorboard/plugins/projector/projector_config.proto\n",
    "config = projector.ProjectorConfig()\n",
    "\n",
    "# You can add multiple embeddings. Here we add only one.\n",
    "embedding_conf = config.embeddings.add()\n",
    "\n",
    "\n",
    "embedding_conf.tensor_name = 'embedding:0'\n",
    "\n",
    "# Link this tensor to its metadata file (e.g. labels).\n",
    "embedding_conf.metadata_path = FOLDER +'/metadata.tsv' \n",
    "\n",
    "# The next line writes a projector_config.pbtxt in the LOG_DIR. TensorBoard will\n",
    "# read this file during startup.\n",
    "projector.visualize_embeddings(summary_writer, config)\n",
    "\n",
    "# save the model\n",
    "saver = tf.train.Saver()\n",
    "saver.save(sess, FOLDER + 'model.ckpt')\n",
    "sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## DOC2VEC INTO A FEED FORWARD DEEP NEURAL NETWORK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## train-test split using scikit-learn\n",
    "X_train, X_test, y_train, y_test = train_test_split(doc_vecs,labels, test_size=.3,\n",
    "                                                  random_state=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Representing our lables as a one hot encoding\n",
    "def one_hot_encode_object_array(arr):\n",
    "    '''One hot encode a numpy array of objects (e.g. strings)'''\n",
    "    uniques, ids = np.unique(arr, return_inverse=True)\n",
    "    return np_utils.to_categorical(ids, len(uniques))\n",
    "\n",
    "train_y_ohe = one_hot_encode_object_array(y_train)\n",
    "test_y_ohe = one_hot_encode_object_array(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"629pt\" viewBox=\"0.00 0.00 175.24 629.00\" width=\"175pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 625)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-625 171.2383,-625 171.2383,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4886826512 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4886826512</title>\n",
       "<polygon fill=\"none\" points=\"0,-584.5 0,-620.5 167.2383,-620.5 167.2383,-584.5 0,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-598.3\">dense_1_input: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4886826064 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4886826064</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-511.5 31.4932,-547.5 135.7451,-547.5 135.7451,-511.5 31.4932,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-525.3\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 4886826512&#45;&gt;4886826064 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4886826512-&gt;4886826064</title>\n",
       "<path d=\"M83.6191,-584.4551C83.6191,-576.3828 83.6191,-566.6764 83.6191,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-557.5903 83.6191,-547.5904 80.1192,-557.5904 87.1192,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4348541328 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4348541328</title>\n",
       "<polygon fill=\"none\" points=\"8.1587,-438.5 8.1587,-474.5 159.0796,-474.5 159.0796,-438.5 8.1587,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-452.3\">activation_1: Activation</text>\n",
       "</g>\n",
       "<!-- 4886826064&#45;&gt;4348541328 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4886826064-&gt;4348541328</title>\n",
       "<path d=\"M83.6191,-511.4551C83.6191,-503.3828 83.6191,-493.6764 83.6191,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-484.5903 83.6191,-474.5904 80.1192,-484.5904 87.1192,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4867705488 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4867705488</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-365.5 31.4932,-401.5 135.7451,-401.5 135.7451,-365.5 31.4932,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-379.3\">dense_2: Dense</text>\n",
       "</g>\n",
       "<!-- 4348541328&#45;&gt;4867705488 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4348541328-&gt;4867705488</title>\n",
       "<path d=\"M83.6191,-438.4551C83.6191,-430.3828 83.6191,-420.6764 83.6191,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-411.5903 83.6191,-401.5904 80.1192,-411.5904 87.1192,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4867703696 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>4867703696</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-292.5 31.4932,-328.5 135.7451,-328.5 135.7451,-292.5 31.4932,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-306.3\">dense_3: Dense</text>\n",
       "</g>\n",
       "<!-- 4867705488&#45;&gt;4867703696 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4867705488-&gt;4867703696</title>\n",
       "<path d=\"M83.6191,-365.4551C83.6191,-357.3828 83.6191,-347.6764 83.6191,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-338.5903 83.6191,-328.5904 80.1192,-338.5904 87.1192,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4896503056 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4896503056</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-219.5 31.4932,-255.5 135.7451,-255.5 135.7451,-219.5 31.4932,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-233.3\">dense_4: Dense</text>\n",
       "</g>\n",
       "<!-- 4867703696&#45;&gt;4896503056 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>4867703696-&gt;4896503056</title>\n",
       "<path d=\"M83.6191,-292.4551C83.6191,-284.3828 83.6191,-274.6764 83.6191,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-265.5903 83.6191,-255.5904 80.1192,-265.5904 87.1192,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4897531216 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>4897531216</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-146.5 31.4932,-182.5 135.7451,-182.5 135.7451,-146.5 31.4932,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-160.3\">dense_5: Dense</text>\n",
       "</g>\n",
       "<!-- 4896503056&#45;&gt;4897531216 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4896503056-&gt;4897531216</title>\n",
       "<path d=\"M83.6191,-219.4551C83.6191,-211.3828 83.6191,-201.6764 83.6191,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-192.5903 83.6191,-182.5904 80.1192,-192.5904 87.1192,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4930097232 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>4930097232</title>\n",
       "<polygon fill=\"none\" points=\"31.4932,-73.5 31.4932,-109.5 135.7451,-109.5 135.7451,-73.5 31.4932,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-87.3\">dense_6: Dense</text>\n",
       "</g>\n",
       "<!-- 4897531216&#45;&gt;4930097232 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>4897531216-&gt;4930097232</title>\n",
       "<path d=\"M83.6191,-146.4551C83.6191,-138.3828 83.6191,-128.6764 83.6191,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-119.5903 83.6191,-109.5904 80.1192,-119.5904 87.1192,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4923227664 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>4923227664</title>\n",
       "<polygon fill=\"none\" points=\"8.1587,-.5 8.1587,-36.5 159.0796,-36.5 159.0796,-.5 8.1587,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"83.6191\" y=\"-14.3\">activation_2: Activation</text>\n",
       "</g>\n",
       "<!-- 4930097232&#45;&gt;4923227664 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>4930097232-&gt;4923227664</title>\n",
       "<path d=\"M83.6191,-73.4551C83.6191,-65.3828 83.6191,-55.6764 83.6191,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"87.1192,-46.5903 83.6191,-36.5904 80.1192,-46.5904 87.1192,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## define our model, deep feed forward network , with the specified units in dense layers\n",
    "model = Sequential()\n",
    "model.add(Dense(1000, input_shape=(10,))) ## Input takes in ten points as we know our doc2vec embeddings are for 10 dimensions\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dense(750, activation='relu'))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(250, activation='relu')) ## activated by the relu finction\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax')) ## activated by the softmax function\n",
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_19 (Dense)             (None, 1000)              11000     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 1000)              1001000   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 750)               750750    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 500)               375500    \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 250)               125250    \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 5)                 1255      \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 2,264,755\n",
      "Trainable params: 2,264,755\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## model is compiled on a categorical_crossentropy loss since it's a multi-class problem, optimized by adam and accuracy as metric\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 10031 samples, validate on 2508 samples\n",
      "Epoch 1/10\n",
      "10031/10031 [==============================] - 9s - loss: 0.9937 - acc: 0.6042 - val_loss: 0.7944 - val_acc: 0.6942\n",
      "Epoch 2/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.7924 - acc: 0.6978 - val_loss: 0.7771 - val_acc: 0.6910\n",
      "Epoch 3/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.7516 - acc: 0.7133 - val_loss: 0.7445 - val_acc: 0.7113\n",
      "Epoch 4/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.7347 - acc: 0.7219 - val_loss: 0.7675 - val_acc: 0.7069\n",
      "Epoch 5/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.7196 - acc: 0.7242 - val_loss: 0.7665 - val_acc: 0.7161\n",
      "Epoch 6/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.6964 - acc: 0.7325 - val_loss: 0.7382 - val_acc: 0.7189\n",
      "Epoch 7/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.6897 - acc: 0.7372 - val_loss: 0.7366 - val_acc: 0.7201\n",
      "Epoch 8/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.6823 - acc: 0.7427 - val_loss: 0.7583 - val_acc: 0.7233\n",
      "Epoch 9/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.6645 - acc: 0.7434 - val_loss: 0.7602 - val_acc: 0.7217\n",
      "Epoch 10/10\n",
      "10031/10031 [==============================] - 8s - loss: 0.6489 - acc: 0.7506 - val_loss: 0.7688 - val_acc: 0.7097\n"
     ]
    }
   ],
   "source": [
    "## fit the model over 10 epochs , specifying the validation split, standard batch size of 128\n",
    "history = model.fit(np.array(X_train), train_y_ohe,\n",
    "                    nb_epoch=10, batch_size=128,\n",
    "                    verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5248/5375 [============================>.] - ETA: 0s"
     ]
    }
   ],
   "source": [
    "## check score on test data\n",
    "score = model.evaluate(np.array(X_test), test_y_ohe,\n",
    "                       batch_size=128, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Test score:', 0.74857067370969199)\n",
      "('Test accuracy:', 0.71255813912458199)\n"
     ]
    }
   ],
   "source": [
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the model predictions\n",
    "y_predicted_arr = model.predict(np.array(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the most probably class prediction of the model\n",
    "y_predicted = []\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## convert the one hot encoding back to original numbered values\n",
    "y_test = []\n",
    "for i in test_y_ohe:\n",
    "    y_test.append(np.where(i == 1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.71255813953488367"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recall score of the model using scikit-learn (true positive/ true positive + false negative)\n",
    "recall_score(y_test, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7140556697511834"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision score of the model using scikit-learn (true positive/ true positive + false positive)\n",
    "precision_score(y_test, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70653446622555138"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## f1-score of the model using scikit-learn (2 * (precision * recall) / (precision + recall))\n",
    "f1_score(y_test, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>reviews(3)</th>\n",
       "      <th>title(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>425</td>\n",
       "      <td>153</td>\n",
       "      <td>85</td>\n",
       "      <td>187</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>647</td>\n",
       "      <td>51</td>\n",
       "      <td>40</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>62</td>\n",
       "      <td>54</td>\n",
       "      <td>1120</td>\n",
       "      <td>53</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>57</td>\n",
       "      <td>80</td>\n",
       "      <td>44</td>\n",
       "      <td>1102</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58</td>\n",
       "      <td>215</td>\n",
       "      <td>87</td>\n",
       "      <td>28</td>\n",
       "      <td>536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  reviews(3)  title(4)\n",
       "0             425             153           85         187       102\n",
       "1              43             647           51          40        88\n",
       "2              62              54         1120          53        30\n",
       "3              57              80           44        1102        28\n",
       "4              58             215           87          28       536"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix that gives us sentences that were predicted correctly and that weren't ( ex : 0th row and 1st column indicates preparation misclassified as an ingredient)\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','reviews(3)','title(4)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Miscellaneous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model =  load_model('autoencoder.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 5, 100)            8424100   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 5, 16)             4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 3, 8)              392       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2, 8)              200       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 8)              200       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2, 8)              200       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 4, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2, 16)             400       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 4, 9)              441       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 185       \n",
      "=================================================================\n",
      "Total params: 8,430,934\n",
      "Trainable params: 6,834\n",
      "Non-trainable params: 8,424,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg height=\"1213pt\" viewBox=\"0.00 0.00 219.61 1213.00\" width=\"220pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g class=\"graph\" id=\"graph0\" transform=\"scale(1 1) rotate(0) translate(4 1209)\">\n",
       "<title>G</title>\n",
       "<polygon fill=\"#ffffff\" points=\"-4,4 -4,-1209 215.6104,-1209 215.6104,4 -4,4\" stroke=\"transparent\"/>\n",
       "<!-- 4999943504 -->\n",
       "<g class=\"node\" id=\"node1\">\n",
       "<title>4999943504</title>\n",
       "<polygon fill=\"none\" points=\"41.624,-1168.5 41.624,-1204.5 169.9863,-1204.5 169.9863,-1168.5 41.624,-1168.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-1182.3\">input_1: InputLayer</text>\n",
       "</g>\n",
       "<!-- 4999942352 -->\n",
       "<g class=\"node\" id=\"node2\">\n",
       "<title>4999942352</title>\n",
       "<polygon fill=\"none\" points=\"23.7344,-1095.5 23.7344,-1131.5 187.876,-1131.5 187.876,-1095.5 23.7344,-1095.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-1109.3\">embedding_1: Embedding</text>\n",
       "</g>\n",
       "<!-- 4999943504&#45;&gt;4999942352 -->\n",
       "<g class=\"edge\" id=\"edge1\">\n",
       "<title>4999943504-&gt;4999942352</title>\n",
       "<path d=\"M105.8052,-1168.4551C105.8052,-1160.3828 105.8052,-1150.6764 105.8052,-1141.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-1141.5903 105.8052,-1131.5904 102.3053,-1141.5904 109.3053,-1141.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4870223440 -->\n",
       "<g class=\"node\" id=\"node3\">\n",
       "<title>4870223440</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-1022.5 42.7793,-1058.5 168.8311,-1058.5 168.8311,-1022.5 42.7793,-1022.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-1036.3\">conv1d_1: Conv1D</text>\n",
       "</g>\n",
       "<!-- 4999942352&#45;&gt;4870223440 -->\n",
       "<g class=\"edge\" id=\"edge2\">\n",
       "<title>4999942352-&gt;4870223440</title>\n",
       "<path d=\"M105.8052,-1095.4551C105.8052,-1087.3828 105.8052,-1077.6764 105.8052,-1068.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-1068.5903 105.8052,-1058.5904 102.3053,-1068.5904 109.3053,-1068.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4674061264 -->\n",
       "<g class=\"node\" id=\"node4\">\n",
       "<title>4674061264</title>\n",
       "<polygon fill=\"none\" points=\"0,-949.5 0,-985.5 211.6104,-985.5 211.6104,-949.5 0,-949.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-963.3\">max_pooling1d_1: MaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 4870223440&#45;&gt;4674061264 -->\n",
       "<g class=\"edge\" id=\"edge3\">\n",
       "<title>4870223440-&gt;4674061264</title>\n",
       "<path d=\"M105.8052,-1022.4551C105.8052,-1014.3828 105.8052,-1004.6764 105.8052,-995.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-995.5903 105.8052,-985.5904 102.3053,-995.5904 109.3053,-995.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5000685584 -->\n",
       "<g class=\"node\" id=\"node5\">\n",
       "<title>5000685584</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-876.5 42.7793,-912.5 168.8311,-912.5 168.8311,-876.5 42.7793,-876.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-890.3\">conv1d_2: Conv1D</text>\n",
       "</g>\n",
       "<!-- 4674061264&#45;&gt;5000685584 -->\n",
       "<g class=\"edge\" id=\"edge4\">\n",
       "<title>4674061264-&gt;5000685584</title>\n",
       "<path d=\"M105.8052,-949.4551C105.8052,-941.3828 105.8052,-931.6764 105.8052,-922.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-922.5903 105.8052,-912.5904 102.3053,-922.5904 109.3053,-922.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4952761296 -->\n",
       "<g class=\"node\" id=\"node6\">\n",
       "<title>4952761296</title>\n",
       "<polygon fill=\"none\" points=\"0,-803.5 0,-839.5 211.6104,-839.5 211.6104,-803.5 0,-803.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-817.3\">max_pooling1d_2: MaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 5000685584&#45;&gt;4952761296 -->\n",
       "<g class=\"edge\" id=\"edge5\">\n",
       "<title>5000685584-&gt;4952761296</title>\n",
       "<path d=\"M105.8052,-876.4551C105.8052,-868.3828 105.8052,-858.6764 105.8052,-849.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-849.5903 105.8052,-839.5904 102.3053,-849.5904 109.3053,-849.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 4870721040 -->\n",
       "<g class=\"node\" id=\"node7\">\n",
       "<title>4870721040</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-730.5 42.7793,-766.5 168.8311,-766.5 168.8311,-730.5 42.7793,-730.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-744.3\">conv1d_3: Conv1D</text>\n",
       "</g>\n",
       "<!-- 4952761296&#45;&gt;4870721040 -->\n",
       "<g class=\"edge\" id=\"edge6\">\n",
       "<title>4952761296-&gt;4870721040</title>\n",
       "<path d=\"M105.8052,-803.4551C105.8052,-795.3828 105.8052,-785.6764 105.8052,-776.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-776.5903 105.8052,-766.5904 102.3053,-776.5904 109.3053,-776.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5013033872 -->\n",
       "<g class=\"node\" id=\"node8\">\n",
       "<title>5013033872</title>\n",
       "<polygon fill=\"none\" points=\"0,-657.5 0,-693.5 211.6104,-693.5 211.6104,-657.5 0,-657.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-671.3\">max_pooling1d_3: MaxPooling1D</text>\n",
       "</g>\n",
       "<!-- 4870721040&#45;&gt;5013033872 -->\n",
       "<g class=\"edge\" id=\"edge7\">\n",
       "<title>4870721040-&gt;5013033872</title>\n",
       "<path d=\"M105.8052,-730.4551C105.8052,-722.3828 105.8052,-712.6764 105.8052,-703.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-703.5903 105.8052,-693.5904 102.3053,-703.5904 109.3053,-703.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5016994960 -->\n",
       "<g class=\"node\" id=\"node9\">\n",
       "<title>5016994960</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-584.5 42.7793,-620.5 168.8311,-620.5 168.8311,-584.5 42.7793,-584.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-598.3\">conv1d_4: Conv1D</text>\n",
       "</g>\n",
       "<!-- 5013033872&#45;&gt;5016994960 -->\n",
       "<g class=\"edge\" id=\"edge8\">\n",
       "<title>5013033872-&gt;5016994960</title>\n",
       "<path d=\"M105.8052,-657.4551C105.8052,-649.3828 105.8052,-639.6764 105.8052,-630.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-630.5903 105.8052,-620.5904 102.3053,-630.5904 109.3053,-630.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5019962704 -->\n",
       "<g class=\"node\" id=\"node10\">\n",
       "<title>5019962704</title>\n",
       "<polygon fill=\"none\" points=\"0,-511.5 0,-547.5 211.6104,-547.5 211.6104,-511.5 0,-511.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-525.3\">up_sampling1d_1: UpSampling1D</text>\n",
       "</g>\n",
       "<!-- 5016994960&#45;&gt;5019962704 -->\n",
       "<g class=\"edge\" id=\"edge9\">\n",
       "<title>5016994960-&gt;5019962704</title>\n",
       "<path d=\"M105.8052,-584.4551C105.8052,-576.3828 105.8052,-566.6764 105.8052,-557.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-557.5903 105.8052,-547.5904 102.3053,-557.5904 109.3053,-557.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5021354832 -->\n",
       "<g class=\"node\" id=\"node11\">\n",
       "<title>5021354832</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-438.5 42.7793,-474.5 168.8311,-474.5 168.8311,-438.5 42.7793,-438.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-452.3\">conv1d_5: Conv1D</text>\n",
       "</g>\n",
       "<!-- 5019962704&#45;&gt;5021354832 -->\n",
       "<g class=\"edge\" id=\"edge10\">\n",
       "<title>5019962704-&gt;5021354832</title>\n",
       "<path d=\"M105.8052,-511.4551C105.8052,-503.3828 105.8052,-493.6764 105.8052,-484.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-484.5903 105.8052,-474.5904 102.3053,-484.5904 109.3053,-484.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5006474320 -->\n",
       "<g class=\"node\" id=\"node12\">\n",
       "<title>5006474320</title>\n",
       "<polygon fill=\"none\" points=\"0,-365.5 0,-401.5 211.6104,-401.5 211.6104,-365.5 0,-365.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-379.3\">up_sampling1d_2: UpSampling1D</text>\n",
       "</g>\n",
       "<!-- 5021354832&#45;&gt;5006474320 -->\n",
       "<g class=\"edge\" id=\"edge11\">\n",
       "<title>5021354832-&gt;5006474320</title>\n",
       "<path d=\"M105.8052,-438.4551C105.8052,-430.3828 105.8052,-420.6764 105.8052,-411.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-411.5903 105.8052,-401.5904 102.3053,-411.5904 109.3053,-411.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5028745488 -->\n",
       "<g class=\"node\" id=\"node13\">\n",
       "<title>5028745488</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-292.5 42.7793,-328.5 168.8311,-328.5 168.8311,-292.5 42.7793,-292.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-306.3\">conv1d_6: Conv1D</text>\n",
       "</g>\n",
       "<!-- 5006474320&#45;&gt;5028745488 -->\n",
       "<g class=\"edge\" id=\"edge12\">\n",
       "<title>5006474320-&gt;5028745488</title>\n",
       "<path d=\"M105.8052,-365.4551C105.8052,-357.3828 105.8052,-347.6764 105.8052,-338.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-338.5903 105.8052,-328.5904 102.3053,-338.5904 109.3053,-338.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5037134672 -->\n",
       "<g class=\"node\" id=\"node14\">\n",
       "<title>5037134672</title>\n",
       "<polygon fill=\"none\" points=\"0,-219.5 0,-255.5 211.6104,-255.5 211.6104,-219.5 0,-219.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-233.3\">up_sampling1d_3: UpSampling1D</text>\n",
       "</g>\n",
       "<!-- 5028745488&#45;&gt;5037134672 -->\n",
       "<g class=\"edge\" id=\"edge13\">\n",
       "<title>5028745488-&gt;5037134672</title>\n",
       "<path d=\"M105.8052,-292.4551C105.8052,-284.3828 105.8052,-274.6764 105.8052,-265.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-265.5903 105.8052,-255.5904 102.3053,-265.5904 109.3053,-265.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5034242640 -->\n",
       "<g class=\"node\" id=\"node15\">\n",
       "<title>5034242640</title>\n",
       "<polygon fill=\"none\" points=\"42.7793,-146.5 42.7793,-182.5 168.8311,-182.5 168.8311,-146.5 42.7793,-146.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-160.3\">conv1d_7: Conv1D</text>\n",
       "</g>\n",
       "<!-- 5037134672&#45;&gt;5034242640 -->\n",
       "<g class=\"edge\" id=\"edge14\">\n",
       "<title>5037134672-&gt;5034242640</title>\n",
       "<path d=\"M105.8052,-219.4551C105.8052,-211.3828 105.8052,-201.6764 105.8052,-192.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-192.5903 105.8052,-182.5904 102.3053,-192.5904 109.3053,-192.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5040102608 -->\n",
       "<g class=\"node\" id=\"node16\">\n",
       "<title>5040102608</title>\n",
       "<polygon fill=\"none\" points=\"50.1724,-73.5 50.1724,-109.5 161.438,-109.5 161.438,-73.5 50.1724,-73.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-87.3\">flatten_1: Flatten</text>\n",
       "</g>\n",
       "<!-- 5034242640&#45;&gt;5040102608 -->\n",
       "<g class=\"edge\" id=\"edge15\">\n",
       "<title>5034242640-&gt;5040102608</title>\n",
       "<path d=\"M105.8052,-146.4551C105.8052,-138.3828 105.8052,-128.6764 105.8052,-119.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-119.5903 105.8052,-109.5904 102.3053,-119.5904 109.3053,-119.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "<!-- 5042226128 -->\n",
       "<g class=\"node\" id=\"node17\">\n",
       "<title>5042226128</title>\n",
       "<polygon fill=\"none\" points=\"53.6792,-.5 53.6792,-36.5 157.9312,-36.5 157.9312,-.5 53.6792,-.5\" stroke=\"#000000\"/>\n",
       "<text fill=\"#000000\" font-family=\"Times,serif\" font-size=\"14.00\" text-anchor=\"middle\" x=\"105.8052\" y=\"-14.3\">dense_1: Dense</text>\n",
       "</g>\n",
       "<!-- 5040102608&#45;&gt;5042226128 -->\n",
       "<g class=\"edge\" id=\"edge16\">\n",
       "<title>5040102608-&gt;5042226128</title>\n",
       "<path d=\"M105.8052,-73.4551C105.8052,-65.3828 105.8052,-55.6764 105.8052,-46.6817\" fill=\"none\" stroke=\"#000000\"/>\n",
       "<polygon fill=\"#000000\" points=\"109.3053,-46.5903 105.8052,-36.5904 102.3053,-46.5904 109.3053,-46.5903\" stroke=\"#000000\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>"
      ],
      "text/plain": [
       "<IPython.core.display.SVG object>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plot_model(model,show_shapes=True, to_file='autoencoder.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py27]",
   "language": "python",
   "name": "Python [py27]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
