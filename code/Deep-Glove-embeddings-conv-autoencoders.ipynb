{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from glove import Corpus, Glove\n",
    "import h5py\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import json\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.cross_validation import  cross_val_score\n",
    "import numpy as np\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from time import time\n",
    "from operator import itemgetter\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.cross_validation import cross_val_predict\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "import scipy\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.utils import np_utils\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.preprocessing import sequence\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import LSTM\n",
    "from keras.layers.convolutional import Convolution1D\n",
    "from keras.layers.convolutional import MaxPooling1D\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.utils import np_utils\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "import math\n",
    "%matplotlib inline\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from collections import Counter\n",
    "import multiprocessing\n",
    "import re\n",
    "np.random.seed(13)\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Embedding, GRU, Input, Bidirectional\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing import sequence\n",
    "from keras.regularizers import l2\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import SVG\n",
    "from keras.utils import plot_model\n",
    "plt.style.use(\"ggplot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "import string\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers.convolutional import Conv1D\n",
    "from keras.layers.core import Flatten,Reshape\n",
    "from keras.models import load_model\n",
    "from keras.layers.wrappers import TimeDistributed\n",
    "from keras.layers import Input, Dense, Conv1D, MaxPooling2D, UpSampling1D\n",
    "from keras.models import Model\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## install glove-python , check if corpus was imported\n",
    "corpus = Corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "glove.corpus.Corpus"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the type\n",
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   data = pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open(\"big_data_label.txt\", \"rb\") as fp:   # Unpickling\n",
    "...   labels = pickle.load(fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_text = ''.join(data) ## covert the list to string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_dataframe_text_stop(article):\n",
    "    \"\"\"\n",
    "    Function that takes text from a dataframe and 1st removes punctuation, returning a list of the processed text in lowercase.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Removing punctuation by checking every character in the text passed to the function.\n",
    "    remove_punctuation = [char for char in article if char not in string.punctuation]\n",
    "   \n",
    "\n",
    "    # Once punctuation has been removed, we join them again to form a string.\n",
    "    remove_punctuation = ''.join(remove_punctuation)\n",
    "    \n",
    "    return [word.lower() for word in remove_punctuation.split()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = process_dataframe_text_stop(data_text) ## the processed text in lower case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame() ## Create a dataframe of the words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['data'] = sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  We create a dataframe and then convert that to a text for the simple reason that glove-python expects a very specific format to train on .\n",
    "##### It requires that the string sequences be stored without inverted commas , one way of doing so was to create a dataframe of words , then convert it back to a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rigatoni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>according</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>package</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>instructions</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>when</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>there</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>just</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>few</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>minutes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>left</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>cooking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>add</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>baby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>broccolini</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>cook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>till</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>forktender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>remove</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>drain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>set</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468615</th>\n",
       "      <td>paulhusmandyanacatcoffeebsharon123karinchianicole</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468616</th>\n",
       "      <td>mcbridetoby</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468617</th>\n",
       "      <td>jermainnajwaratherbeswimminnifpaulagtwississte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468618</th>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468619</th>\n",
       "      <td>hopeleslielalaloulalauralie41dreamgoddessweekend</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468620</th>\n",
       "      <td>cookeropal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468621</th>\n",
       "      <td>fitzgeraldalways</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468622</th>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468623</th>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468624</th>\n",
       "      <td>kitchen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468625</th>\n",
       "      <td>connienorthwestgalkaren</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468626</th>\n",
       "      <td>elizabethlavender</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468627</th>\n",
       "      <td>lynnbdmk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468628</th>\n",
       "      <td>grace</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468629</th>\n",
       "      <td>parisi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468630</th>\n",
       "      <td>lori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468631</th>\n",
       "      <td>powell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468632</th>\n",
       "      <td>lorrie</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468633</th>\n",
       "      <td>corvin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468634</th>\n",
       "      <td>lori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468635</th>\n",
       "      <td>powell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468636</th>\n",
       "      <td>hunter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468637</th>\n",
       "      <td>lewis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468638</th>\n",
       "      <td>david</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468639</th>\n",
       "      <td>bonom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468640</th>\n",
       "      <td>amy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468641</th>\n",
       "      <td>machnak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468642</th>\n",
       "      <td>lori</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468643</th>\n",
       "      <td>powell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468644</th>\n",
       "      <td>foodcomfoodcomfoodcomfoodcomfoodcomfoodcomfood...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>468645 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     data\n",
       "0                                                    cook\n",
       "1                                                     the\n",
       "2                                                rigatoni\n",
       "3                                               according\n",
       "4                                                      to\n",
       "5                                                     the\n",
       "6                                                 package\n",
       "7                                            instructions\n",
       "8                                                    when\n",
       "9                                                   there\n",
       "10                                                     is\n",
       "11                                                   just\n",
       "12                                                      a\n",
       "13                                                    few\n",
       "14                                                minutes\n",
       "15                                                   left\n",
       "16                                                     of\n",
       "17                                                cooking\n",
       "18                                                    add\n",
       "19                                                    the\n",
       "20                                                   baby\n",
       "21                                             broccolini\n",
       "22                                                    and\n",
       "23                                                   cook\n",
       "24                                                   till\n",
       "25                                             forktender\n",
       "26                                                 remove\n",
       "27                                                  drain\n",
       "28                                                    and\n",
       "29                                                    set\n",
       "...                                                   ...\n",
       "468615  paulhusmandyanacatcoffeebsharon123karinchianicole\n",
       "468616                                        mcbridetoby\n",
       "468617  jermainnajwaratherbeswimminnifpaulagtwississte...\n",
       "468618                                            kitchen\n",
       "468619   hopeleslielalaloulalauralie41dreamgoddessweekend\n",
       "468620                                         cookeropal\n",
       "468621                                   fitzgeraldalways\n",
       "468622                                                 in\n",
       "468623                                                the\n",
       "468624                                            kitchen\n",
       "468625                            connienorthwestgalkaren\n",
       "468626                                  elizabethlavender\n",
       "468627                                           lynnbdmk\n",
       "468628                                              grace\n",
       "468629                                             parisi\n",
       "468630                                               lori\n",
       "468631                                             powell\n",
       "468632                                             lorrie\n",
       "468633                                             corvin\n",
       "468634                                               lori\n",
       "468635                                             powell\n",
       "468636                                             hunter\n",
       "468637                                              lewis\n",
       "468638                                              david\n",
       "468639                                              bonom\n",
       "468640                                                amy\n",
       "468641                                            machnak\n",
       "468642                                               lori\n",
       "468643                                             powell\n",
       "468644  foodcomfoodcomfoodcomfoodcomfoodcomfoodcomfood...\n",
       "\n",
       "[468645 rows x 1 columns]"
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Convert the dataframe to a list , row wise \n",
    "sentences_final=[]\n",
    "\n",
    "for row in df.iterrows():\n",
    "    index, data = row\n",
    "    sentences_final.append(data.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## fit the model with a window size of 10\n",
    "corpus.fit(sentences_final, window=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Specify the learning rate and the number of components\n",
    "glove = Glove(no_components=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing 50 training epochs with 4 threads\n",
      "Epoch 0\n",
      "Epoch 1\n",
      "Epoch 2\n",
      "Epoch 3\n",
      "Epoch 4\n",
      "Epoch 5\n",
      "Epoch 6\n",
      "Epoch 7\n",
      "Epoch 8\n",
      "Epoch 9\n",
      "Epoch 10\n",
      "Epoch 11\n",
      "Epoch 12\n",
      "Epoch 13\n",
      "Epoch 14\n",
      "Epoch 15\n",
      "Epoch 16\n",
      "Epoch 17\n",
      "Epoch 18\n",
      "Epoch 19\n",
      "Epoch 20\n",
      "Epoch 21\n",
      "Epoch 22\n",
      "Epoch 23\n",
      "Epoch 24\n",
      "Epoch 25\n",
      "Epoch 26\n",
      "Epoch 27\n",
      "Epoch 28\n",
      "Epoch 29\n",
      "Epoch 30\n",
      "Epoch 31\n",
      "Epoch 32\n",
      "Epoch 33\n",
      "Epoch 34\n",
      "Epoch 35\n",
      "Epoch 36\n",
      "Epoch 37\n",
      "Epoch 38\n",
      "Epoch 39\n",
      "Epoch 40\n",
      "Epoch 41\n",
      "Epoch 42\n",
      "Epoch 43\n",
      "Epoch 44\n",
      "Epoch 45\n",
      "Epoch 46\n",
      "Epoch 47\n",
      "Epoch 48\n",
      "Epoch 49\n"
     ]
    }
   ],
   "source": [
    "## We train our glove over 50 epochs running 4 threads in parallel\n",
    "glove.fit(corpus.matrix, epochs=50, no_threads=4, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Create a dictionary\n",
    "glove.add_dictionary(corpus.dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'issues.': 44455,\n",
       " 'anise': 8115,\n",
       " 'minutes.Grill': 8701,\n",
       " 'begins,': 16536,\n",
       " 'grapes250': 21769,\n",
       " 'fryapril': 68197,\n",
       " 'pointyou': 55644,\n",
       " '282total': 64370,\n",
       " 'saladsmixed': 73460,\n",
       " 'highplace': 53992,\n",
       " '15177': 67809,\n",
       " 'lids': 318,\n",
       " 'wuite': 35923,\n",
       " '\"if': 45640,\n",
       " 'mg(24%)Polyunsaturated': 31674,\n",
       " 'favoritesused': 70912,\n",
       " '148': 64098,\n",
       " 'cooked.Add': 12617,\n",
       " 'street.': 44560,\n",
       " 'crumbsshake': 57870,\n",
       " 'postingso': 71303,\n",
       " 'persillade': 12288,\n",
       " 'saladwafflesbacon': 73588,\n",
       " 'g12sodium': 66192,\n",
       " 'Pizzas': 50111,\n",
       " 'tamalessalt': 22570,\n",
       " 'hr.period,I': 45443,\n",
       " 'cauliflowerkeep': 59021,\n",
       " 'marinade.Broil': 7946,\n",
       " 'Stern,': 36438,\n",
       " 'want?': 39472,\n",
       " 'covered.Drain': 14287,\n",
       " 'Jones,': 37485,\n",
       " 'CasseroleSpaghettini': 49821,\n",
       " 'paperoptional': 62158,\n",
       " 'stewlike': 72111,\n",
       " 'raisins1⁄2': 21808,\n",
       " '287.9': 30752,\n",
       " '!!': 39364,\n",
       " 'pulp,': 9660,\n",
       " 'chopper.': 14545,\n",
       " '455': 63705,\n",
       " 'SaladSmoking': 48959,\n",
       " 'ice.Grate': 10222,\n",
       " 'contains': 35626,\n",
       " 'ahead': 2607,\n",
       " '(230': 11422,\n",
       " 'Dining': 40544,\n",
       " 'keeping.': 37048,\n",
       " 'Tender': 39168,\n",
       " 'hold': 796,\n",
       " 'wanted.TO': 15260,\n",
       " 'oatmeal.': 13109,\n",
       " 'equals': 36458,\n",
       " 'SandwichesBig': 49227,\n",
       " 'spinage': 25212,\n",
       " 'stalks.': 1221,\n",
       " 'marine': 69522,\n",
       " '350°in': 52455,\n",
       " '*Everyday': 45470,\n",
       " 'Oilsalt': 25864,\n",
       " 'totalwash': 53026,\n",
       " 'dough!': 40255,\n",
       " 'asada': 75738,\n",
       " '78.5': 29384,\n",
       " 'combined.Heat': 12641,\n",
       " 'linkszucchini': 73733,\n",
       " '5379calories': 66990,\n",
       " 'BrittleRoasted': 50536,\n",
       " '539': 65400,\n",
       " 'velveeta.': 3363,\n",
       " 'stopsdust': 59301,\n",
       " 'forks': 14318,\n",
       " 'etcadd': 53431,\n",
       " 'sauce)1': 22071,\n",
       " 'middle': 595,\n",
       " 'g3monounsaturated': 65918,\n",
       " 'pepper8': 21140,\n",
       " 'orangesstir': 56651,\n",
       " 'F.Let': 9420,\n",
       " 'YOLKS,': 16464,\n",
       " 'chillies.': 1843,\n",
       " 'time.Cut': 42099,\n",
       " 'sauce28': 21968,\n",
       " 'busy,': 34690,\n",
       " 'used--the': 40962,\n",
       " 'combinedfill': 52854,\n",
       " 'cheese!': 36238,\n",
       " 'chipsusing': 60779,\n",
       " 'steam.Return': 11393,\n",
       " 'towel.Arrange': 11751,\n",
       " 'overnightif': 51941,\n",
       " '350.Drain': 15523,\n",
       " 'ENDED': 43961,\n",
       " 'slivers1': 22952,\n",
       " 'restaurantsyummyadding': 71109,\n",
       " 'louisianaHal': 51304,\n",
       " 'janbevritachef': 76384,\n",
       " 'melts.Heat': 15616,\n",
       " 'spead': 15367,\n",
       " 'boxnot': 69906,\n",
       " 'oilthinly': 54295,\n",
       " 'ChiliFarfalle': 50592,\n",
       " '1671calories': 64758,\n",
       " 'posted.This': 45677,\n",
       " 'moisturein': 59530,\n",
       " 'RangePancakes': 48729,\n",
       " 'reads': 6923,\n",
       " 'opinion,': 43375,\n",
       " 'fast,': 13407,\n",
       " 'returned': 35425,\n",
       " 'over.Pinch': 14576,\n",
       " 'container.Remove': 7280,\n",
       " 'coconutbake': 57203,\n",
       " '462.6': 33116,\n",
       " '283total': 65135,\n",
       " 'mandarins': 41869,\n",
       " '4-8': 10720,\n",
       " 'weck': 74508,\n",
       " 'working,': 14687,\n",
       " 'serveto': 51441,\n",
       " '865': 65314,\n",
       " '243calories': 66805,\n",
       " 'powder.Beat': 12648,\n",
       " '515calories': 64050,\n",
       " 'towels1': 63177,\n",
       " 'hamthis': 68872,\n",
       " 'spicy,': 34790,\n",
       " 'joes-frozen)1': 25409,\n",
       " 'gentle': 614,\n",
       " 'BeegirlvlynnSD': 51244,\n",
       " 'cabbage': 7051,\n",
       " 'snack/eats': 45073,\n",
       " 'ingredientsconfectioners': 61377,\n",
       " 'cuisine.': 36600,\n",
       " '(peeled,': 21568,\n",
       " '32.8': 30312,\n",
       " '51': 32094,\n",
       " 'cooker.After': 10140,\n",
       " 'doughi': 53707,\n",
       " 'minutes).Serve.Drain,': 18799,\n",
       " 'neededground': 21868,\n",
       " 'rolls.': 11777,\n",
       " '1396calories': 67448,\n",
       " 'flamencooriented': 69445,\n",
       " 'packed1⁄2': 22608,\n",
       " 'broth/water,': 15204,\n",
       " 'thickness2': 63406,\n",
       " '163total': 64348,\n",
       " 'milkfor': 63144,\n",
       " '28oz': 63244,\n",
       " 'not.Make': 6806,\n",
       " 'independent': 70809,\n",
       " 'hortelãxarope': 24984,\n",
       " 'creamwatermelon': 74334,\n",
       " 'ChiliAnytime': 48960,\n",
       " 'lovers’': 73652,\n",
       " '750-ml': 25791,\n",
       " 'pickles': 9459,\n",
       " 'enclose': 12212,\n",
       " 'hoursboil': 52096,\n",
       " 'RitaNice': 41190,\n",
       " 'pinto': 19993,\n",
       " 'steaksplace': 57281,\n",
       " '107.9': 30306,\n",
       " 'seasoningstransfer': 58267,\n",
       " 'easy!mustardyThis': 44700,\n",
       " 'chilled10': 26640,\n",
       " '1214': 51861,\n",
       " 'sauceheat': 52795,\n",
       " '13x9x2-inch': 3536,\n",
       " 'medium.Drain': 9113,\n",
       " 'refrigerator.Remove': 19694,\n",
       " '350°spray': 53474,\n",
       " 'stars.': 41555,\n",
       " '341.9': 30165,\n",
       " 'chipsred': 21441,\n",
       " 'web.Found': 34548,\n",
       " 'brim': 54391,\n",
       " 'quiches': 17970,\n",
       " 'ficarem': 11626,\n",
       " 'recipe!Low': 42787,\n",
       " '1210calories': 67227,\n",
       " 'suited': 34607,\n",
       " 'parmesean': 12309,\n",
       " 'quickly': 160,\n",
       " 'board;': 19457,\n",
       " '2714.8': 32204,\n",
       " '333.5': 32673,\n",
       " '32gthis': 68438,\n",
       " 'boil.cook': 6892,\n",
       " '1336': 65553,\n",
       " 'edgesmix': 59451,\n",
       " 'coating': 3740,\n",
       " 'Package,': 9161,\n",
       " 'eggs.In': 4736,\n",
       " 'korea': 70654,\n",
       " 'StewPfeffernuesse': 48791,\n",
       " 'howev...I': 47753,\n",
       " 'sh...This': 44212,\n",
       " 'crystalsGraham': 20174,\n",
       " 'bickley508': 56054,\n",
       " 'CranberriesBYU': 48490,\n",
       " 'emulsified,': 13286,\n",
       " 'dinnermake': 68890,\n",
       " 'shintanis': 69579,\n",
       " '2727calories': 63534,\n",
       " 'bath.Cool': 15936,\n",
       " 'Kahlua/brandy.Assembly:': 7532,\n",
       " '63.8': 30424,\n",
       " 'asleep.': 43616,\n",
       " 'superior.': 44991,\n",
       " '6138calories': 64308,\n",
       " 'potatoescook': 56180,\n",
       " 'package.': 4107,\n",
       " 'discard.Top': 17424,\n",
       " 'dry14': 61999,\n",
       " 'Russian': 35187,\n",
       " 'bacon20': 61872,\n",
       " 'more': 929,\n",
       " 'Version': 48694,\n",
       " 'here’s': 69518,\n",
       " 'diagonallyin': 53039,\n",
       " 'tempthis': 70643,\n",
       " 'though.My': 41597,\n",
       " '350°F.Prick': 13706,\n",
       " 'Broil': 4082,\n",
       " 'sauceput': 58583,\n",
       " 'cheese,': 342,\n",
       " 'vanillastir': 52003,\n",
       " 'chopped12': 23649,\n",
       " 'J!Love': 43676,\n",
       " 'fastthis': 71649,\n",
       " 'thermometerlet': 56795,\n",
       " 'daughter.': 41572,\n",
       " 'slicedVine': 25471,\n",
       " 'paperscrape': 58801,\n",
       " 'mug': 12107,\n",
       " 'optional12': 61956,\n",
       " 'postingfabulous': 72586,\n",
       " '1246.4': 33423,\n",
       " 'bettydont': 70687,\n",
       " ':-)': 38184,\n",
       " 'russiantype': 70034,\n",
       " 'concerned.': 45889,\n",
       " 'Hochbrueckner,': 40242,\n",
       " 'bath.Whisk': 14656,\n",
       " \"LasagnaLaura's\": 49628,\n",
       " 'cool.Transfer': 16613,\n",
       " 'marinadeput': 54698,\n",
       " 'desertlike': 69398,\n",
       " '220.1': 31040,\n",
       " '553.9': 33023,\n",
       " 'Rump': 21117,\n",
       " 'oilfine': 61103,\n",
       " 'yummyfrom': 69988,\n",
       " 'freegreat': 69851,\n",
       " 'heads2': 63338,\n",
       " 'said.': 40504,\n",
       " 'Rich': 36668,\n",
       " '(egg': 20753,\n",
       " 'salt/peppering': 10479,\n",
       " 'avocado.Serve': 16415,\n",
       " 'leaves5': 23584,\n",
       " 'jelled1': 63147,\n",
       " 'degreestransfer': 57758,\n",
       " 'bonom': 76026,\n",
       " 'tastewater,': 22918,\n",
       " 'clean.': 2319,\n",
       " 'BEST': 34621,\n",
       " 'bowlslowly': 52766,\n",
       " 'bacon.Add': 18037,\n",
       " 'refrigerate.Note:': 14268,\n",
       " 'bananas1⁄2': 23933,\n",
       " 'Combined': 44213,\n",
       " 'ricota': 25567,\n",
       " 'layer.Spread': 9128,\n",
       " 'jalepenos.': 44550,\n",
       " 'heinz': 53703,\n",
       " '6823': 64985,\n",
       " 'institute': 69562,\n",
       " '5fix': 67972,\n",
       " 'completelyrinse': 60055,\n",
       " 'g(30%)Fat': 31612,\n",
       " 'bacontoss': 12185,\n",
       " 'rosemary1⁄4': 20794,\n",
       " 'creambeat': 58493,\n",
       " 'peanuts1⁄3': 28421,\n",
       " '1504Calories': 33601,\n",
       " 'smoothcook': 56543,\n",
       " '198total': 64472,\n",
       " 'Buddy': 49549,\n",
       " 'weeksif': 53316,\n",
       " 'tortellini.Simmer': 4435,\n",
       " 'overwow': 71009,\n",
       " 'pureed5': 24171,\n",
       " 'America': 39287,\n",
       " 'thawed1': 19965,\n",
       " 'Mizithra': 40793,\n",
       " 'asidethinly': 53218,\n",
       " 'RoastCurried': 48505,\n",
       " 'onion,': 381,\n",
       " 'mixtureafter': 60195,\n",
       " 'smoothienanas': 74273,\n",
       " 'griller': 71770,\n",
       " '108.7': 32901,\n",
       " 'smoothiepw': 75400,\n",
       " 'fruit;': 4570,\n",
       " 'Prawn': 50477,\n",
       " 'drain.Meanwhile,': 6526,\n",
       " 'room.Chill': 13450,\n",
       " 'regular/plain': 46159,\n",
       " 'brownrewarm': 60492,\n",
       " 'meatless': 5465,\n",
       " 'softenedTopping2': 22129,\n",
       " 'taste)Filling1': 21522,\n",
       " 'base.Bake': 14564,\n",
       " 'StewSpiralized': 49591,\n",
       " 'blueberries': 8670,\n",
       " 'wafflesheat': 60818,\n",
       " 'ballsmake': 57796,\n",
       " 'planningi': 68130,\n",
       " 'garlic),': 17024,\n",
       " 'rice;': 17537,\n",
       " 'stumbled': 46213,\n",
       " 'blend.add': 16154,\n",
       " 'dough.When': 2055,\n",
       " 'original,': 39621,\n",
       " 'minutessift': 55634,\n",
       " '73.9Calories': 29221,\n",
       " 'MIX3': 22979,\n",
       " 'recipeFrom': 35414,\n",
       " 'halfandhalf3⁄4': 63204,\n",
       " 'cream.Place': 16111,\n",
       " 'bunco': 41885,\n",
       " '(1-oz.': 21226,\n",
       " '(seeded': 26417,\n",
       " '(50': 22694,\n",
       " 'dough:In': 13188,\n",
       " 'pickachef': 72551,\n",
       " 'SEMI-DEHYDRATED': 46336,\n",
       " 'ReynoldsPhil': 50732,\n",
       " '14total': 63911,\n",
       " '2468calories': 67264,\n",
       " 'toothpickcool': 60625,\n",
       " 'Tempeh': 49546,\n",
       " 'desired.Drain': 15835,\n",
       " 'pineappleremove': 54771,\n",
       " 'chance': 15465,\n",
       " 'applebrbrinstead': 73285,\n",
       " 'coolTo': 15548,\n",
       " 'oozing.Serve': 4601,\n",
       " 'second': 2849,\n",
       " 'minutesprepare': 52887,\n",
       " 'posting!Pizza': 46872,\n",
       " 'convection': 4251,\n",
       " 'OK.Made': 43922,\n",
       " 'cucumbers': 3758,\n",
       " 'bushes.': 37167,\n",
       " 'film': 5233,\n",
       " 'piped': 2910,\n",
       " 'dustfried': 74733,\n",
       " 'TomatoesGrilled': 48736,\n",
       " '9.': 1873,\n",
       " 'coatadd': 59424,\n",
       " 'potatochopped': 23654,\n",
       " 'scallops.One': 11377,\n",
       " 'CakeSausage': 48795,\n",
       " 'blend;': 2621,\n",
       " 'mustard.Heat': 15695,\n",
       " \"ben's\": 23305,\n",
       " 'moistrinse': 57734,\n",
       " 'Montana,': 39010,\n",
       " 'pot-stickers,': 35071,\n",
       " 'warmavailable': 56463,\n",
       " 'eatingwellcom': 68939,\n",
       " '1717': 65188,\n",
       " 'cup.': 6332,\n",
       " 'SauerkrautCottage': 48827,\n",
       " 'similar,': 46174,\n",
       " '792calories': 65635,\n",
       " 'cheesein': 54683,\n",
       " '322.1': 33307,\n",
       " 'dollar).Place': 9828,\n",
       " 'dried)salt': 11912,\n",
       " 'sliceschop': 55326,\n",
       " 'squeezedfresh': 28200,\n",
       " 'CondimentsSoups,': 47816,\n",
       " 'recipeenjoyed': 72615,\n",
       " 'set.Let': 7698,\n",
       " 'chiles1': 62140,\n",
       " 'gingernuts:)': 46776,\n",
       " 'mixturekeep': 55338,\n",
       " 'Imperial': 38438,\n",
       " 'well.Toss': 5772,\n",
       " 'toss.Melt': 11324,\n",
       " '5652': 64580,\n",
       " 'distinctly': 35145,\n",
       " 'meatlike': 70737,\n",
       " 'medium)2': 27757,\n",
       " '2t': 56708,\n",
       " 'wine)salt': 22981,\n",
       " 'coolfry': 53984,\n",
       " '60.6': 30250,\n",
       " 'long': 1042,\n",
       " 'manrebbiebelizabethknicelyevelynathensgrandmaiscookingmichelle': 75749,\n",
       " 'maldonextravirgin': 62010,\n",
       " 'minutereduce': 59177,\n",
       " 'soft.Squeeze': 18934,\n",
       " 'heaping1⁄2': 63398,\n",
       " '5556': 65739,\n",
       " 'cajungirl': 68132,\n",
       " 'milk.This': 39986,\n",
       " 'ingredients.When': 7704,\n",
       " 'heart14': 61936,\n",
       " 'thankyou': 72647,\n",
       " 'pickled': 9460,\n",
       " '3203': 66915,\n",
       " 'saltchill': 59812,\n",
       " 'stock': 1426,\n",
       " 'pot.STIR': 5971,\n",
       " 'smell.This': 43879,\n",
       " 'thursday': 71314,\n",
       " 'paste440': 27957,\n",
       " '710minutes': 51714,\n",
       " 'carrots1⁄2': 20921,\n",
       " 'toasty.': 11789,\n",
       " 'drainedritz': 63255,\n",
       " 'creamy.Spoon': 7264,\n",
       " 'CelerySausage': 50172,\n",
       " 'ground': 1101,\n",
       " 'sugar56': 25731,\n",
       " 'constantlypour': 60814,\n",
       " 'glass.Add': 18706,\n",
       " 'porkSalt': 20362,\n",
       " 'reality:': 41114,\n",
       " 'employeekeeps': 69433,\n",
       " 'gretchen': 76192,\n",
       " 'I...This': 44982,\n",
       " '625': 67194,\n",
       " 'mushroomslettuce': 75579,\n",
       " 'bourbon6': 61474,\n",
       " '375°': 6920,\n",
       " '10608calories': 64696,\n",
       " 'disapearallow': 53711,\n",
       " 'bake': 292,\n",
       " 'knifeplace': 53328,\n",
       " 'solids': 8619,\n",
       " 'cold.Line': 12079,\n",
       " 'mind!': 44901,\n",
       " 'paraathasheat': 55240,\n",
       " 'days;': 13379,\n",
       " 'hock': 44619,\n",
       " 'mayjune': 68646,\n",
       " '325F': 12109,\n",
       " 'quichechocolate': 74022,\n",
       " 'better!This': 41706,\n",
       " 'leaves025': 61784,\n",
       " 'links)oreganosalt': 22985,\n",
       " '80455': 63792,\n",
       " '2-5': 3957,\n",
       " '2797': 63758,\n",
       " 'PecansStrawberry': 50227,\n",
       " '265.2Calories': 33365,\n",
       " 'stengels.Snipper': 12692,\n",
       " 'taste).At': 5179,\n",
       " 'smoothbring': 56145,\n",
       " 'Claims': 34480,\n",
       " 'flan': 7094,\n",
       " '1143': 65622,\n",
       " 'gm5': 61566,\n",
       " '(12-cup)': 13075,\n",
       " '4856calories': 65346,\n",
       " '3702calories': 67664,\n",
       " 'restaurateur': 39203,\n",
       " 'Banana': 13345,\n",
       " \"SoufflesMommy's\": 49446,\n",
       " 'orqnge': 8874,\n",
       " \"J's\": 42444,\n",
       " '85.8': 31420,\n",
       " 'feldmanrecipenutcastanaann': 75847,\n",
       " 'Nuggets': 50557,\n",
       " 'scale.Add': 6993,\n",
       " 'flavornever': 72053,\n",
       " 'aside.Directions': 5005,\n",
       " 'scissors,': 10654,\n",
       " 'immediately.Mary': 11183,\n",
       " 'over': 63,\n",
       " '2932': 65462,\n",
       " 'delightcrock': 75199,\n",
       " 'kabobs.': 43179,\n",
       " 'gets).Stir': 17990,\n",
       " 'additives': 42884,\n",
       " 'onion6': 24278,\n",
       " 'experience': 38272,\n",
       " 'inspires': 44390,\n",
       " 'Shred': 12472,\n",
       " 'secondsor': 72681,\n",
       " 'taxichicken': 75536,\n",
       " 'muir': 61018,\n",
       " \"thanks.I've\": 44051,\n",
       " '1612': 64508,\n",
       " 'considerably': 42421,\n",
       " 'wishas': 60792,\n",
       " 'months': 13926,\n",
       " '392.8Calories': 31190,\n",
       " 'up!love': 39957,\n",
       " 'numberherb': 27454,\n",
       " 'satisfaction': 35920,\n",
       " 'Enjoy!My': 36464,\n",
       " 'balls.Place': 7839,\n",
       " 'perfect': 5819,\n",
       " 'bottle': 1004,\n",
       " 'ironpour': 53714,\n",
       " 'surfacecut': 52269,\n",
       " 'posteasy': 72259,\n",
       " 'BeefVegan': 48588,\n",
       " 'chuck': 14838,\n",
       " 'glaze,': 6592,\n",
       " 'slicedolive': 26390,\n",
       " 'sets.Frost': 19248,\n",
       " 'g(12%)Saturated': 31552,\n",
       " 'nowbut': 69286,\n",
       " 'Duh.)Drizzle': 1836,\n",
       " 'mediumlow': 51738,\n",
       " 'wear': 2263,\n",
       " 'peppers3⁄4': 27588,\n",
       " 'Heatter;': 34866,\n",
       " 'vegetablesarrange': 56521,\n",
       " '512.8': 30314,\n",
       " 'Jewish': 36325,\n",
       " 'seedgarlicparmesan': 26996,\n",
       " '338Total': 30282,\n",
       " 'cheese/pepperoni': 10603,\n",
       " '6oz.': 16370,\n",
       " 'combine.Transfer': 8946,\n",
       " 'Parmigiano-Reggiano12': 25491,\n",
       " '245Total': 30392,\n",
       " 'VERSIONS': 43950,\n",
       " 'hourspuree': 53160,\n",
       " 'foils': 15590,\n",
       " 'settingdeseed': 57466,\n",
       " 'fatconscious': 68552,\n",
       " 'salsa.You': 6284,\n",
       " 'ffry': 53371,\n",
       " 'bologna1': 61448,\n",
       " '¾-inch-thick': 17958,\n",
       " 'foams,': 11086,\n",
       " 'Medal™': 20133,\n",
       " 'havarti': 22232,\n",
       " 'trimmed2': 21929,\n",
       " 'chips5': 24168,\n",
       " 'Topping:1/4': 25190,\n",
       " 'bowls': 1306,\n",
       " 'chicken.Preheat': 3032,\n",
       " 'canes,': 12178,\n",
       " '\\x93quickie\\x94': 69278,\n",
       " 'peppers1': 21128,\n",
       " '(optional)Dressing:1/2': 24246,\n",
       " '547': 64670,\n",
       " 'glue': 54069,\n",
       " 'minutes).Flip': 4674,\n",
       " 'remainer': 38397,\n",
       " 'isle': 56729,\n",
       " 'goldenserve': 52164,\n",
       " 'memoriesthis': 68757,\n",
       " 'pan;': 2722,\n",
       " 'onion)': 42301,\n",
       " 'Semolina': 46645,\n",
       " 'sandwich!': 39171,\n",
       " 'mayo1': 25236,\n",
       " 'aji': 72402,\n",
       " 'salmontransfer': 55611,\n",
       " 'blackberries1⁄2': 27523,\n",
       " 'overprocess': 12067,\n",
       " 'hr,': 13661,\n",
       " 'egg12': 62773,\n",
       " 'ASP.': 34132,\n",
       " 'tails2': 26218,\n",
       " 'jello/tapioca': 45022,\n",
       " 'salsa.This': 44546,\n",
       " 'oil1': 20302,\n",
       " 'toohe': 73122,\n",
       " 'minutesscoop': 57616,\n",
       " 'activates': 13189,\n",
       " 'baking.This': 36122,\n",
       " 'BreadVegetarian': 49566,\n",
       " 'onionmeat': 53332,\n",
       " 'skinjerk': 74193,\n",
       " '375º.': 1956,\n",
       " 'incorporating': 4507,\n",
       " '683.4': 31412,\n",
       " 'minutes.Mix': 219,\n",
       " '34318': 67004,\n",
       " 'spices1⁄4': 22100,\n",
       " '17605': 64916,\n",
       " 'hgi': 73127,\n",
       " 'cleantransfer': 57237,\n",
       " 'cloves3': 21127,\n",
       " 'whisk.Stir': 4686,\n",
       " 'dry.Pile': 13373,\n",
       " 'everyoneloved': 45311,\n",
       " '2c': 18228,\n",
       " 'alcohol,': 45501,\n",
       " '(milk': 23376,\n",
       " '394.7': 30594,\n",
       " 'rinsed2': 23169,\n",
       " '7362calories': 67603,\n",
       " 'shallot': 12981,\n",
       " 'approximate.)1': 28553,\n",
       " 'Chusta': 49254,\n",
       " 'addedmade': 71532,\n",
       " '881': 67709,\n",
       " 'platessurround': 52109,\n",
       " 'gets': 1998,\n",
       " 'saladwe': 74377,\n",
       " 'Some': 13472,\n",
       " 'Mojito': 12831,\n",
       " 'fingers,': 7870,\n",
       " 'buttersprinkle': 55227,\n",
       " 'humid': 2916,\n",
       " 'reached': 1926,\n",
       " 'gently.Place': 3410,\n",
       " 'bottomif': 57601,\n",
       " 'sutter': 62936,\n",
       " 'saladside': 73461,\n",
       " 'plate.Preheat': 6218,\n",
       " 'using)Pour': 13957,\n",
       " 'cakepour': 58116,\n",
       " 'wet,': 4898,\n",
       " 'freeze-dry': 18052,\n",
       " '243Calories': 32652,\n",
       " 'stuffing.Stir': 5287,\n",
       " 'gunsaturatedFatContent': 31442,\n",
       " 'non-metallic': 17986,\n",
       " 'sauteoriental': 73640,\n",
       " '1145': 65758,\n",
       " 'Onions.': 45557,\n",
       " 'serve.Cook': 7699,\n",
       " 'lunchtime': 41072,\n",
       " '612.6': 33249,\n",
       " 'greensFishPork': 26001,\n",
       " 'more\"': 45313,\n",
       " 'better': 2148,\n",
       " 'butter;': 4704,\n",
       " 'smoothly': 4363,\n",
       " 'mixture.into': 6613,\n",
       " 'nut1': 22197,\n",
       " 'patience': 36794,\n",
       " 'diagonalslice': 60382,\n",
       " 'tahini1⁄2': 28251,\n",
       " 'fashioned': 5943,\n",
       " 'brown.Note:': 16722,\n",
       " 'raspberries.Good!': 46840,\n",
       " '2536': 67347,\n",
       " 'parchmentlined': 51995,\n",
       " 'extrafirm': 60940,\n",
       " 'Eve': 36710,\n",
       " 'g(33%)Saturated': 31952,\n",
       " 'g31sodium': 65849,\n",
       " '6467calories': 66402,\n",
       " '742Total': 33694,\n",
       " 'GenieSiddTasteTester**': 51373,\n",
       " 'tipsthis': 69427,\n",
       " '1081': 30616,\n",
       " '278Calories': 33488,\n",
       " 'BisqueHoney': 48423,\n",
       " '55total': 64356,\n",
       " 'peashoppin’': 62731,\n",
       " 'COMPLETELY': 14633,\n",
       " '6199calories': 64721,\n",
       " 'oventhis': 68186,\n",
       " 'montrealenglishrosebackwoods': 75754,\n",
       " \"1970's\": 36025,\n",
       " '1762calories': 66599,\n",
       " 'Contest': 33974,\n",
       " 'SoupSix-Pack': 49589,\n",
       " 'diet': 22356,\n",
       " 'coated': 1861,\n",
       " 'sprinkles,': 20167,\n",
       " 'extract;': 11243,\n",
       " 'garnish)14': 26163,\n",
       " 'floats': 13339,\n",
       " 'desired)3': 24148,\n",
       " 'juiceslow': 74001,\n",
       " '1296': 63983,\n",
       " '392': 31993,\n",
       " 'cinnamonin': 52002,\n",
       " 'bowl.Float': 6252,\n",
       " 'gcarbohydratecontent': 65784,\n",
       " 'pepper1412': 60938,\n",
       " ':)Really': 44794,\n",
       " 'saltlet': 60167,\n",
       " 'necessaryhalf': 53433,\n",
       " 'cholesterolg155': 57184,\n",
       " '20.4': 29727,\n",
       " 'bastingthe': 13334,\n",
       " 'rocks-it': 46348,\n",
       " 'far!The': 8697,\n",
       " 'shake.Get': 19107,\n",
       " 'raspbery': 17621,\n",
       " '14inch': 51994,\n",
       " 'choppedDressing1⁄2': 28361,\n",
       " 'canmild': 23780,\n",
       " '359': 64284,\n",
       " 'hoursstir': 51806,\n",
       " 'AAACover': 14533,\n",
       " 'or1': 22319,\n",
       " 'motionwhen': 51976,\n",
       " 'dividing': 8657,\n",
       " 'saucepanturn': 56270,\n",
       " '(quartered)1': 21233,\n",
       " 'rum15': 20864,\n",
       " '28Total': 29854,\n",
       " '76total': 63784,\n",
       " \"WenchMessy44gailanngscarleyratherbeswimmin'Abba\": 51246,\n",
       " 'preservesfinish': 60528,\n",
       " 'half250': 21767,\n",
       " 'blancwhite': 62297,\n",
       " 'once.': 2288,\n",
       " 'again.Spoon': 13753,\n",
       " 'lava.': 2870,\n",
       " '1632.3': 29843,\n",
       " 'mix12': 27369,\n",
       " 'Anaheim': 26062,\n",
       " 'overall!!': 41135,\n",
       " 'garlic;': 1128,\n",
       " 'africarecipe': 68691,\n",
       " '\"quac\"': 39407,\n",
       " 'fillto': 57871,\n",
       " '411carbohydrates': 66248,\n",
       " 'parboiled': 27010,\n",
       " 'GirlMsSallyKittencal@recipezazzLisa1getfitkateParrot': 50909,\n",
       " '180°f': 51825,\n",
       " 'thrift': 38180,\n",
       " 'Salt1/4': 25061,\n",
       " '4-6': 74,\n",
       " 'PaneerTomato-Avocado': 49311,\n",
       " '500°': 56088,\n",
       " '407Calories': 30203,\n",
       " 'WrapMustard': 50052,\n",
       " 'Plus': 35778,\n",
       " 'parsleycook': 52008,\n",
       " 'oil/milk/': 8508,\n",
       " 'Stinking': 35747,\n",
       " 'this....2': 46197,\n",
       " 'servingroll': 57955,\n",
       " 'cutting.': 12350,\n",
       " 'translucentremove': 53894,\n",
       " '400.cook': 12291,\n",
       " 'stickydrop': 53071,\n",
       " 'jarswide': 61114,\n",
       " 'PAC.Although': 42626,\n",
       " 'extracts': 18520,\n",
       " 'Thanks!Ok,': 42250,\n",
       " 'gratedcashews': 21389,\n",
       " 'heat.Cover': 2653,\n",
       " 'smooth.Return': 12064,\n",
       " 'washington': 72218,\n",
       " '298.4Calories': 33036,\n",
       " 'artisanal1': 61503,\n",
       " 'fish,': 7559,\n",
       " 'Freezes': 35868,\n",
       " 'baklavaglutenfree': 75732,\n",
       " 'g16monounsaturated': 66213,\n",
       " 'eggs1/4': 24712,\n",
       " '1246Total': 29106,\n",
       " 'handama': 75217,\n",
       " 'pepper1⁄8': 22723,\n",
       " 'zwtp': 72959,\n",
       " '54total': 63601,\n",
       " 'dislike': 41683,\n",
       " 'paste.Heat': 16228,\n",
       " 'pan.Loosen': 7523,\n",
       " 'Shaved': 36204,\n",
       " 'Marlene': 50934,\n",
       " 'degrees.Meanwhile': 15755,\n",
       " 'well.Stir': 9018,\n",
       " '291carbohydrates': 65938,\n",
       " 'layerstop': 53748,\n",
       " 'flavors;': 40204,\n",
       " 'MushroomsCheese': 48720,\n",
       " 'carameltofu': 74471,\n",
       " 'asparagas': 24847,\n",
       " '400Total': 29997,\n",
       " 'milanorobin': 75818,\n",
       " 'serving.From': 37517,\n",
       " 'boil.Repeat': 4235,\n",
       " 'sausages1': 22406,\n",
       " 'breadsfiha': 75425,\n",
       " 'turnovers': 75252,\n",
       " '318Carbohydrates': 31784,\n",
       " 'powder1⁄41⁄2': 63151,\n",
       " 'bangkok': 70570,\n",
       " 'dry.Preheat': 15009,\n",
       " 'beegirlvlynnsd': 76308,\n",
       " 'ChopsCreamy': 48506,\n",
       " '0calories': 63622,\n",
       " 'basilstep': 53909,\n",
       " 'basilboil': 60768,\n",
       " 'on2': 23058,\n",
       " 'andersons': 69003,\n",
       " 'fillingheat': 51725,\n",
       " 'loosened,': 2215,\n",
       " 'pale.Spread': 15826,\n",
       " 'crabmeatset': 53896,\n",
       " 'messed': 39178,\n",
       " 'pan.Just': 19284,\n",
       " 'Original': 8068,\n",
       " 'stock.Preheat': 18257,\n",
       " 'Vegetables.Deep': 3192,\n",
       " 'g111protein': 65829,\n",
       " 'remain.Using': 2732,\n",
       " 'prmr': 70825,\n",
       " '204.5Calories': 29687,\n",
       " 'apples.': 1297,\n",
       " '4424': 64345,\n",
       " 'circulars.': 39518,\n",
       " 'cups),': 25489,\n",
       " 'finelysalt': 21638,\n",
       " 'vegetables1': 26518,\n",
       " 'skim1': 63212,\n",
       " \"'original'\": 22689,\n",
       " 'Granola': 48354,\n",
       " 'refrigerator1': 51681,\n",
       " '(I': 386,\n",
       " 'foillined': 53419,\n",
       " 'cold),': 6961,\n",
       " 'deem': 74009,\n",
       " 'moon.': 19896,\n",
       " '68.3': 30554,\n",
       " 'drained1': 21150,\n",
       " '180cgas': 52967,\n",
       " 'Juenessa.Great': 43290,\n",
       " 'Suggests': 40034,\n",
       " '89.3': 29833,\n",
       " 'chilies1': 20789,\n",
       " '230.4': 30083,\n",
       " '\"traditional\"': 34396,\n",
       " ',keep': 17763,\n",
       " 'sage9': 21946,\n",
       " 'heat.Fry': 11479,\n",
       " '34.7': 30868,\n",
       " 'me.This': 40589,\n",
       " '160c': 60003,\n",
       " 'honey6': 23051,\n",
       " 'cleansaute': 53954,\n",
       " '1021calories': 64234,\n",
       " 'topping': 2736,\n",
       " '56.8Calories': 32895,\n",
       " 'heatthen': 52876,\n",
       " 'warmarrange': 60856,\n",
       " 'achelived).COMBINE': 17743,\n",
       " 'pureed.Add': 4560,\n",
       " '350PF.Proceed': 17710,\n",
       " '535carbohydrates': 66171,\n",
       " '143º,': 18536,\n",
       " 'g96protein': 65875,\n",
       " 'Pennsylvania.': 40446,\n",
       " 'thin.Brush': 19459,\n",
       " 'cloves.Boil': 10226,\n",
       " 'cranberriesbyu': 73964,\n",
       " '1391': 67456,\n",
       " 'combinereturn': 53088,\n",
       " '1567calories': 64475,\n",
       " 'skilletadd': 52612,\n",
       " 'pepperscombine': 60243,\n",
       " 'smoothie.': 41339,\n",
       " 'receipe.': 44144,\n",
       " 'cleaned,': 23957,\n",
       " 'Simplest': 48461,\n",
       " 'Jessie': 13265,\n",
       " 'tortillaroll': 59598,\n",
       " '(360Â°F)': 2254,\n",
       " 'coriander,': 2302,\n",
       " 'florentinepeach': 74232,\n",
       " 'coredseededand': 62999,\n",
       " 'avacodo': 46510,\n",
       " '25min.Frosting': 19769,\n",
       " 'cornflour': 1233,\n",
       " 'gently.Chill': 3882,\n",
       " '240.7Calories': 31315,\n",
       " 'Orange-Ginger': 48801,\n",
       " '113.4Calories': 32978,\n",
       " 'onionsdrizzle': 55868,\n",
       " 'CasseroleAdzuki': 48594,\n",
       " 'burned.': 40948,\n",
       " 'melts.': 9764,\n",
       " 'stalk1⁄2': 63031,\n",
       " 'pot.Sprinkle': 19423,\n",
       " 'hackettsfamilySubmitted': 50984,\n",
       " '6.Prepare': 8992,\n",
       " 'pepper12': 25389,\n",
       " 'TAKE': 12562,\n",
       " 'wwwallrecipescom': 69182,\n",
       " 'ginger-garlic': 16972,\n",
       " 'simmered\".Add': 15164,\n",
       " 'paprika;': 2757,\n",
       " 'crusty.Combine': 11249,\n",
       " 'pureed.Divide': 8879,\n",
       " 'sanbusa': 35591,\n",
       " '350ºF': 15004,\n",
       " '8397.1': 30388,\n",
       " 'saladslice': 51928,\n",
       " '396total': 64803,\n",
       " 'bowl.Form': 11477,\n",
       " 'BakeGingerbread': 49101,\n",
       " 'together.Set': 4444,\n",
       " 'side.This': 39021,\n",
       " '2qt': 4917,\n",
       " '1/3-inch': 24080,\n",
       " 'memorable).': 47366,\n",
       " '(alternatively,': 2256,\n",
       " '6-inch': 9673,\n",
       " 'unsweetened1⁄3': 63364,\n",
       " 'soufflégingersnap': 73691,\n",
       " 'tried!': 41745,\n",
       " 'sprayfresh': 21600,\n",
       " '742.4': 29598,\n",
       " 'foodwe': 68817,\n",
       " 'Dee': 34992,\n",
       " '77Total': 28899,\n",
       " 'rind.Combine': 16175,\n",
       " 'cumin3⁄8': 22857,\n",
       " 'meatballs,': 3620,\n",
       " 'towels.Add': 6547,\n",
       " 'cream.Soften': 5525,\n",
       " 'color)': 8551,\n",
       " 'container.*beat': 11950,\n",
       " 'Enjoy!Combine': 53,\n",
       " 'dozen': 21695,\n",
       " 'exellent': 44124,\n",
       " 'and...WOW': 44556,\n",
       " 'gloucester': 61207,\n",
       " 'eachotherpour': 59383,\n",
       " 'one!': 36810,\n",
       " 'minutescoolpick': 52414,\n",
       " 'brown.Spoon': 10862,\n",
       " 'whipcombine': 60529,\n",
       " 'rolls.From': 35967,\n",
       " 'an…225g': 25878,\n",
       " '\"Magic': 49435,\n",
       " 'upwhen': 58747,\n",
       " 'cornmeal)1': 23485,\n",
       " 'taste)salt,': 21999,\n",
       " 'garlicbeat': 57472,\n",
       " 'CookiesBreadQuick': 47904,\n",
       " '277carbohydrates': 66217,\n",
       " 'midnight.': 42070,\n",
       " 'using.Chocolate': 38859,\n",
       " 'Dad,': 43745,\n",
       " 'MarinaraSausage': 50599,\n",
       " 'inch.Add': 10947,\n",
       " 'thorstens': 71233,\n",
       " 'Bias-cut': 4379,\n",
       " 'tofuthis': 70662,\n",
       " 'spray.Mash': 8473,\n",
       " 'periodafter': 60694,\n",
       " '1398.6': 31055,\n",
       " 'assembling': 7857,\n",
       " 'ButterDeath': 50235,\n",
       " 'aja': 23440,\n",
       " 'sisterhood': 69860,\n",
       " 'beauty.': 46964,\n",
       " '400°F).If': 13609,\n",
       " 'brazilian': 68527,\n",
       " 'tomatoes,pinto': 14979,\n",
       " 'bigger': 34720,\n",
       " 'fresno': 26060,\n",
       " \"'breading'\": 46500,\n",
       " 'skillet2': 23787,\n",
       " 'lime)1': 21248,\n",
       " 'minutes\\x95': 56336,\n",
       " 'flakes2': 21014,\n",
       " 'enjoys.': 34611,\n",
       " 'bowl.Spread': 9252,\n",
       " 'tortillastaco': 61193,\n",
       " 'immediately.Mix': 6408,\n",
       " 'helpers': 71508,\n",
       " 'currysmell': 72665,\n",
       " 'mushrooms.': 3851,\n",
       " 'lasagnafennel': 75299,\n",
       " 'soupegg': 73675,\n",
       " 'cream.Melt': 18575,\n",
       " 'foilserve': 55424,\n",
       " 'tortillas.A': 34272,\n",
       " 'peeled)3': 26583,\n",
       " 'FraicheNut-Crusted': 50142,\n",
       " '491Total': 32972,\n",
       " 'tastecanola': 62857,\n",
       " 'greasyrich': 72428,\n",
       " 'spray2.Melt': 13573,\n",
       " '206.7Calories': 30495,\n",
       " 'andenjoyin': 60050,\n",
       " 'francies': 70580,\n",
       " '8-12': 13055,\n",
       " '442Carbohydrates': 32088,\n",
       " 'shredded)1': 27554,\n",
       " '18599': 66852,\n",
       " '3181calories': 66840,\n",
       " ...}"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Having a look at ur dictionry\n",
    "corpus.dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('leaf', 0.4527839605958866),\n",
       " ('dusting)2', 0.41637258058230436),\n",
       " ('jerk.', 0.40736172455012659),\n",
       " ('cardamom2⁄3', 0.40619726945068096),\n",
       " ('gratedfilling', 0.39101176348116778),\n",
       " ('sauce.Process', 0.38159963775997036),\n",
       " ('Creme', 0.37377211683935302),\n",
       " ('workin', 0.37052583522508847),\n",
       " ('tomatoes.Reduce', 0.36514131496064539),\n",
       " ('8349calories', 0.36425106329294965),\n",
       " ('wheat2', 0.36395938521343701),\n",
       " ('ovencool', 0.36155851311421472),\n",
       " ('\"Buffalo', 0.35993351644955868),\n",
       " ('in.If', 0.35765852913271934),\n",
       " ('\"Mens', 0.35340908235345481),\n",
       " ('1285', 0.35335904092497344),\n",
       " ('elaiaksubmitted', 0.35148626977387099),\n",
       " ('coloring,', 0.35114604477344658),\n",
       " ('divided1', 0.34776491529641873)]"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## getting the most similar words to cook\n",
    "glove.most_similar('cook',number=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Glove embedded layer into convolutional , lstm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keras preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(lower=True) ## initialise tokenizer\n",
    "tokenizer.fit_on_texts(data)      ## fit it on our data\n",
    "sequences = tokenizer.texts_to_sequences(data) ## obtain our sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 84240 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "## unique tokens in our data\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## setting the max length of our sentences\n",
    "MAX_SEQUENCE_LENGTH = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## pad the sequences so that they are of the same length\n",
    "data1 = pad_sequences(sequences,maxlen = MAX_SEQUENCE_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (920695, 5)\n",
      "Shape of label tensor: (920695, 5)\n"
     ]
    }
   ],
   "source": [
    "## one hot encoding of the labels\n",
    "labels1 = to_categorical(np.asarray(labels))\n",
    "print('Shape of data tensor:', data1.shape)\n",
    "print('Shape of label tensor:', labels1.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## specify test split \n",
    "TEST_SPLIT = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## we manually specified the test , train and validation split \n",
    "indices = np.arange(data1.shape[0])\n",
    "np.random.shuffle(indices) ## shuffle our data so that we don't feed them in order or provide the same pattern\n",
    "data1 = data1[indices]\n",
    "labels1 = labels1[indices]\n",
    "nb_test_samples = int(TEST_SPLIT * data1.shape[0])\n",
    "## specify our train test split\n",
    "x_train = data1[:-nb_test_samples]\n",
    "y_train = labels1[:-nb_test_samples]\n",
    "x_test = data1[-nb_test_samples:]\n",
    "y_test = labels1[-nb_test_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_split = 0.2 ## validation split\n",
    "nb_validation_data = int(val_split * x_train.shape[0]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## validation data\n",
    "x_val = x_train[-nb_validation_data:]\n",
    "y_val = y_train[-nb_validation_data:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((736556, 5), (184139, 5))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the shapes\n",
    "x_train.shape,x_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((147311, 5), (147311, 5))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## check the validation shapes\n",
    "x_val.shape,x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "## load our pre-trained glove embedding of the wiki corpus\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join('glove.6B', 'glove.6B.100d.txt'))\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "\n",
    "print('Found %s word vectors.' % len(embeddings_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## specify the dimensions for embedding\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Create an embedding matrix \n",
    "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
    "for word, i in word_index.items(): ## word in unique token\n",
    "    embedding_vector = embeddings_index.get(word) ## get the vector for that word from pre-trained\n",
    "    if embedding_vector is not None:\n",
    "        # words not found in embedding index will be all-zeros.\n",
    "        embedding_matrix[i] = embedding_vector ## add in the vectors if found else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Specify our very own keras layer(glove embedding)\n",
    "embedding_layer = Embedding(len(word_index) + 1,\n",
    "                            EMBEDDING_DIM,\n",
    "                            weights=[embedding_matrix],\n",
    "                            input_length=MAX_SEQUENCE_LENGTH,\n",
    "                            trainable=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refer spyder-gpu notebook for the best architecture , this is a mere experimentation although it produced good results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 795,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py34/lib/python3.4/site-packages/ipykernel/__main__.py:13: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "//anaconda/envs/py34/lib/python3.4/site-packages/ipykernel/__main__.py:13: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(128, return_sequences=True, input_shape=(10, 64))`\n"
     ]
    }
   ],
   "source": [
    "## carried out using the keras api\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "x = Conv1D(128, 2, activation='relu')(embedded_sequences) ## conv layer 128 filters with a size of 2\n",
    "x = MaxPooling1D(1)(x)\n",
    "x = Conv1D(100, 1, activation='relu')(x)\n",
    "x = MaxPooling1D(1)(x)\n",
    "x = Conv1D(75, 1, activation='relu')(x)\n",
    "x = MaxPooling1D(1)(x)  # global max pooling\n",
    "x = Dropout(0.2)(x)\n",
    "x = Conv1D(75, 1, activation='relu')(x)\n",
    "x = MaxPooling1D(1)(x)  # global max pooling\n",
    "x = GRU(128, input_dim=64, input_length=10, return_sequences=True)(x) ## GRU is a simple lstm layer\n",
    "x = TimeDistributed(Dense(128, activation='relu'))(x) ## time distributed dense to go over the entire sequence\n",
    "x = Dropout(0.2)(x)\n",
    "x = Flatten()(x)\n",
    "preds = Dense(9, activation='sigmoid')(x)\n",
    "model = Model(sequence_input, preds)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 796,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_95 (InputLayer)        (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_11 (Embedding)     (None, 5, 100)            1532300   \n",
      "_________________________________________________________________\n",
      "conv1d_249 (Conv1D)          (None, 4, 128)            25728     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_231 (MaxPoolin (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_250 (Conv1D)          (None, 4, 100)            12900     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_232 (MaxPoolin (None, 4, 100)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_251 (Conv1D)          (None, 4, 75)             7575      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_233 (MaxPoolin (None, 4, 75)             0         \n",
      "_________________________________________________________________\n",
      "dropout_78 (Dropout)         (None, 4, 75)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_252 (Conv1D)          (None, 4, 75)             5700      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_234 (MaxPoolin (None, 4, 75)             0         \n",
      "_________________________________________________________________\n",
      "gru_29 (GRU)                 (None, 4, 128)            78336     \n",
      "_________________________________________________________________\n",
      "time_distributed_18 (TimeDis (None, 4, 128)            16512     \n",
      "_________________________________________________________________\n",
      "dropout_79 (Dropout)         (None, 4, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_35 (Flatten)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_104 (Dense)            (None, 9)                 4617      \n",
      "=================================================================\n",
      "Total params: 1,683,668\n",
      "Trainable params: 151,368\n",
      "Non-trainable params: 1,532,300\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 798,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 46650 samples, validate on 9330 samples\n",
      "Epoch 1/60\n",
      "46650/46650 [==============================] - 19s - loss: 1.0735 - acc: 0.3818 - val_loss: 0.6577 - val_acc: 0.5488\n",
      "Epoch 2/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.6554 - acc: 0.5494 - val_loss: 0.5892 - val_acc: 0.5766\n",
      "Epoch 3/60\n",
      "46650/46650 [==============================] - 15s - loss: 0.6094 - acc: 0.5693 - val_loss: 0.5612 - val_acc: 0.5861\n",
      "Epoch 4/60\n",
      "46650/46650 [==============================] - 15s - loss: 0.5725 - acc: 0.6106 - val_loss: 0.5288 - val_acc: 0.5966\n",
      "Epoch 5/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.5420 - acc: 0.6268 - val_loss: 0.5049 - val_acc: 0.6397\n",
      "Epoch 6/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.5257 - acc: 0.6675 - val_loss: 0.4874 - val_acc: 0.7469\n",
      "Epoch 7/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.3237 - acc: 0.8834 - val_loss: 0.2726 - val_acc: 0.9040\n",
      "Epoch 8/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.2918 - acc: 0.8965 - val_loss: 0.2558 - val_acc: 0.9116\n",
      "Epoch 9/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.2780 - acc: 0.9000 - val_loss: 0.2478 - val_acc: 0.9128\n",
      "Epoch 10/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.2677 - acc: 0.9051 - val_loss: 0.2357 - val_acc: 0.9184\n",
      "Epoch 11/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.2545 - acc: 0.9091 - val_loss: 0.2267 - val_acc: 0.9222\n",
      "Epoch 12/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2478 - acc: 0.9118 - val_loss: 0.2356 - val_acc: 0.9211\n",
      "Epoch 13/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2372 - acc: 0.9150 - val_loss: 0.2104 - val_acc: 0.9295\n",
      "Epoch 14/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2294 - acc: 0.9175 - val_loss: 0.2023 - val_acc: 0.9330\n",
      "Epoch 15/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2205 - acc: 0.9205 - val_loss: 0.1988 - val_acc: 0.9323\n",
      "Epoch 16/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2151 - acc: 0.9230 - val_loss: 0.1892 - val_acc: 0.9355\n",
      "Epoch 17/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2059 - acc: 0.9261 - val_loss: 0.1853 - val_acc: 0.9350\n",
      "Epoch 18/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.2025 - acc: 0.9273 - val_loss: 0.1856 - val_acc: 0.9339\n",
      "Epoch 19/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1958 - acc: 0.9297 - val_loss: 0.1784 - val_acc: 0.9375\n",
      "Epoch 20/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1897 - acc: 0.9312 - val_loss: 0.1671 - val_acc: 0.9419\n",
      "Epoch 21/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1863 - acc: 0.9322 - val_loss: 0.1626 - val_acc: 0.9437\n",
      "Epoch 22/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1840 - acc: 0.9334 - val_loss: 0.1557 - val_acc: 0.9472\n",
      "Epoch 23/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1777 - acc: 0.9352 - val_loss: 0.1608 - val_acc: 0.9437\n",
      "Epoch 24/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1716 - acc: 0.9381 - val_loss: 0.1505 - val_acc: 0.9480\n",
      "Epoch 25/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1674 - acc: 0.9397 - val_loss: 0.1518 - val_acc: 0.9478\n",
      "Epoch 26/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1639 - acc: 0.9400 - val_loss: 0.1460 - val_acc: 0.9506\n",
      "Epoch 27/60\n",
      "46650/46650 [==============================] - 20s - loss: 0.1634 - acc: 0.9402 - val_loss: 0.1407 - val_acc: 0.9519\n",
      "Epoch 28/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1555 - acc: 0.9434 - val_loss: 0.1359 - val_acc: 0.9537\n",
      "Epoch 29/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1544 - acc: 0.9435 - val_loss: 0.1321 - val_acc: 0.9549\n",
      "Epoch 30/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1532 - acc: 0.9443 - val_loss: 0.1399 - val_acc: 0.9524\n",
      "Epoch 31/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1496 - acc: 0.9455 - val_loss: 0.1371 - val_acc: 0.9504\n",
      "Epoch 32/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1473 - acc: 0.9456 - val_loss: 0.1316 - val_acc: 0.9540\n",
      "Epoch 33/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1434 - acc: 0.9471 - val_loss: 0.1276 - val_acc: 0.9559\n",
      "Epoch 34/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1425 - acc: 0.9476 - val_loss: 0.1268 - val_acc: 0.9557\n",
      "Epoch 35/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1378 - acc: 0.9499 - val_loss: 0.1237 - val_acc: 0.9567\n",
      "Epoch 36/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1351 - acc: 0.9498 - val_loss: 0.1172 - val_acc: 0.9594\n",
      "Epoch 37/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1333 - acc: 0.9503 - val_loss: 0.1218 - val_acc: 0.9574\n",
      "Epoch 38/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1313 - acc: 0.9515 - val_loss: 0.1186 - val_acc: 0.9580\n",
      "Epoch 39/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1313 - acc: 0.9511 - val_loss: 0.1191 - val_acc: 0.9594\n",
      "Epoch 40/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1319 - acc: 0.9514 - val_loss: 0.1181 - val_acc: 0.9581\n",
      "Epoch 41/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1254 - acc: 0.9532 - val_loss: 0.1147 - val_acc: 0.9600\n",
      "Epoch 42/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1230 - acc: 0.9547 - val_loss: 0.1180 - val_acc: 0.9578\n",
      "Epoch 43/60\n",
      "46650/46650 [==============================] - 18s - loss: 0.1246 - acc: 0.9534 - val_loss: 0.1096 - val_acc: 0.9623\n",
      "Epoch 44/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1230 - acc: 0.9544 - val_loss: 0.1062 - val_acc: 0.9632\n",
      "Epoch 45/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.1227 - acc: 0.9545 - val_loss: 0.1134 - val_acc: 0.9594\n",
      "Epoch 46/60\n",
      "46650/46650 [==============================] - 1428s - loss: 0.1207 - acc: 0.9550 - val_loss: 0.1129 - val_acc: 0.9596\n",
      "Epoch 47/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1178 - acc: 0.9563 - val_loss: 0.1055 - val_acc: 0.9639\n",
      "Epoch 48/60\n",
      "46650/46650 [==============================] - 16s - loss: 0.1172 - acc: 0.9573 - val_loss: 0.0986 - val_acc: 0.9653\n",
      "Epoch 49/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1171 - acc: 0.9559 - val_loss: 0.0955 - val_acc: 0.9668\n",
      "Epoch 50/60\n",
      "46650/46650 [==============================] - 15s - loss: 0.1136 - acc: 0.9570 - val_loss: 0.0993 - val_acc: 0.9641\n",
      "Epoch 51/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1137 - acc: 0.9577 - val_loss: 0.1023 - val_acc: 0.9640\n",
      "Epoch 52/60\n",
      "46650/46650 [==============================] - 25s - loss: 0.1113 - acc: 0.9575 - val_loss: 0.0954 - val_acc: 0.9666\n",
      "Epoch 53/60\n",
      "46650/46650 [==============================] - 25s - loss: 0.1163 - acc: 0.9564 - val_loss: 0.1002 - val_acc: 0.9644\n",
      "Epoch 54/60\n",
      "46650/46650 [==============================] - 19s - loss: 0.1103 - acc: 0.9590 - val_loss: 0.0974 - val_acc: 0.9655\n",
      "Epoch 55/60\n",
      "46650/46650 [==============================] - 27s - loss: 0.1112 - acc: 0.9583 - val_loss: 0.1025 - val_acc: 0.9638\n",
      "Epoch 56/60\n",
      "46650/46650 [==============================] - 22s - loss: 0.1076 - acc: 0.9597 - val_loss: 0.0888 - val_acc: 0.9681\n",
      "Epoch 57/60\n",
      "46650/46650 [==============================] - 23s - loss: 0.1075 - acc: 0.9593 - val_loss: 0.0913 - val_acc: 0.9683\n",
      "Epoch 58/60\n",
      "46650/46650 [==============================] - 22s - loss: 0.1076 - acc: 0.9591 - val_loss: 0.0915 - val_acc: 0.9677\n",
      "Epoch 59/60\n",
      "46650/46650 [==============================] - 21s - loss: 0.1057 - acc: 0.9600 - val_loss: 0.0911 - val_acc: 0.9682\n",
      "Epoch 60/60\n",
      "46650/46650 [==============================] - 20s - loss: 0.1045 - acc: 0.9605 - val_loss: 0.0915 - val_acc: 0.9671\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x19e410048>"
      ]
     },
     "execution_count": 798,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## fit over 60 epochs , produces great results\n",
    "model.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
    "          epochs=60,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11648/11662 [============================>.] - ETA: 0s"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.53587615099542141, 0.88972731950945028]"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## evaluate the model over the test data\n",
    "model.evaluate(x_test, y_test,\n",
    "                       verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the model predictions\n",
    "y_predicted_arr = model.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Get the most probably class prediction of the model\n",
    "y_predicted = []\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## convert the one hot encoding back to original numbered values\n",
    "y_test_labels = []\n",
    "for i in y_test:\n",
    "    y_test_labels.append(np.where(i==1)[0][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 8, 2, 1, 3, 2, 0, 1, 2, 2], [1, 7, 2, 1, 3, 2, 0, 1, 2, 2])"
      ]
     },
     "execution_count": 877,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## having a look at a few predictions , seems pretty good\n",
    "y_predicted[:10],y_test_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88972731949922823"
      ]
     },
     "execution_count": 880,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recall score of the model using scikit-learn (true positive/ true positive + false negative)\n",
    "recall_score(y_test_labels, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89461908989947214"
      ]
     },
     "execution_count": 881,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision score of the model using scikit-learn (true positive/ true positive + false positive)\n",
    "precision_score(y_test_labels, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 882,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.88802113193849552"
      ]
     },
     "execution_count": 882,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## f1-score of the model using scikit-learn (2 * (precision * recall) / (precision + recall))\n",
    "f1_score(y_test_labels, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 883,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>description(3)</th>\n",
       "      <th>reviews(4)</th>\n",
       "      <th>tags(5)</th>\n",
       "      <th>title(6)</th>\n",
       "      <th>author(7)</th>\n",
       "      <th>crawler_name(8)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2182</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "      <td>72</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113</td>\n",
       "      <td>3463</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>26</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3461</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>27</td>\n",
       "      <td>2</td>\n",
       "      <td>125</td>\n",
       "      <td>78</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>67</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>84</td>\n",
       "      <td>270</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>33</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>257</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>170</td>\n",
       "      <td>167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  description(3)  reviews(4)  \\\n",
       "0            2182             130            3              72          47   \n",
       "1             113            3463            1              31           8   \n",
       "2               1               0         3461               0           0   \n",
       "3              75              27            2             125          78   \n",
       "4              67              22            0              84         270   \n",
       "5               0               4            0               0           0   \n",
       "6              33              61            0              30           8   \n",
       "7               4              11            0               5           1   \n",
       "8               0               0            0               0           0   \n",
       "\n",
       "   tags(5)  title(6)  author(7)  crawler_name(8)  \n",
       "0        8         7          3               60  \n",
       "1       10        26          3                3  \n",
       "2        0         0          0                0  \n",
       "3        0        12          4                2  \n",
       "4        0         4          3                1  \n",
       "5       78         2          1                0  \n",
       "6       17       257         18                4  \n",
       "7        6         7        170              167  \n",
       "8        0         0          0              370  "
      ]
     },
     "execution_count": 883,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix that gives us sentences that were predicted correctly and that weren't ( ex : 0th row and 1st column indicates preparation misclassified as an ingredient)\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test_labels,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','description(3)','reviews(4)','tags(5)','title(6)','author(7)','crawler_name(8)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and predict on the scrapped data from a website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 888,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to disk\n"
     ]
    }
   ],
   "source": [
    "## save the model for later use \n",
    "model.save(\"glove-keras.h5\")\n",
    "print(\"Saved model to disk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## we can try saving the weights only and not the entire model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 935,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.save_weights(\"weights.h5py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 936,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## function to buil the model with the loaded weights\n",
    "def build_model():\n",
    "    sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "    embedded_sequences = embedding_layer(sequence_input)\n",
    "    x = Conv1D(128, 2, activation='relu')(embedded_sequences)\n",
    "    x = MaxPooling1D(1)(x)\n",
    "    x = Conv1D(100, 1, activation='relu')(x)\n",
    "    x = MaxPooling1D(1)(x)\n",
    "    x = Conv1D(75, 1, activation='relu')(x)\n",
    "    x = MaxPooling1D(1)(x)  # global max pooling\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv1D(75, 1, activation='relu')(x)\n",
    "    x = MaxPooling1D(1)(x)  # global max pooling\n",
    "    x = GRU(128, input_dim=64, input_length=10, return_sequences=True)(x)\n",
    "    x = TimeDistributed(Dense(128, activation='relu'))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    preds = Dense(9, activation='softmax')(x)\n",
    "\n",
    "    model = Model(sequence_input, preds)\n",
    "    model.load_weights(\"weights.h5py\")\n",
    "    return model\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 937,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda/envs/py34/lib/python3.4/site-packages/ipykernel/__main__.py:14: UserWarning: The `input_dim` and `input_length` arguments in recurrent layers are deprecated. Use `input_shape` instead.\n",
      "//anaconda/envs/py34/lib/python3.4/site-packages/ipykernel/__main__.py:14: UserWarning: Update your `GRU` call to the Keras 2 API: `GRU(128, return_sequences=True, input_shape=(10, 64))`\n"
     ]
    }
   ],
   "source": [
    "## build and compile the new model\n",
    "model_2= build_model()\n",
    "model_2.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 938,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## use model to predict\n",
    "syn_arr = model_2.predict(data2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "## the architectures for encoding and decoding have to be the similar\n",
    "## encoding using conv1d and max pooling 1d\n",
    "x = Conv1D(16, (3), activation='relu', padding='same')(embedded_sequences)\n",
    "x = MaxPooling1D((2), padding='same')(x) ## pool important features\n",
    "x = Conv1D(8, (3), activation='relu', padding='same')(x)\n",
    "x = MaxPooling1D((2), padding='same')(x)\n",
    "x = Conv1D(8, (3), activation='relu', padding='same')(x)\n",
    "encoded = MaxPooling1D((2), padding='same')(x)\n",
    "\n",
    "## decoding using conv1d and upsampling 1d\n",
    "x = Conv1D(8, (3), activation='relu', padding='same')(encoded)\n",
    "x = UpSampling1D((2))(x) ## repeats each time step by the size specified\n",
    "x = Conv1D(8, (3), activation='relu', padding='same')(x)\n",
    "x = UpSampling1D((2))(x)\n",
    "x = Conv1D(16, (3), activation='relu')(x)\n",
    "x = UpSampling1D((2))(x)\n",
    "## pass through conv1d and dense to make predictions\n",
    "x = Conv1D(9, (3), activation='relu')(x)\n",
    "x = Flatten()(x)\n",
    "preds = Dense(5, activation='softmax')(x)\n",
    "\n",
    "autoencoder = Model(sequence_input, preds)\n",
    "autoencoder.compile(optimizer='adadelta', loss='categorical_crossentropy') ## optmised with adadelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 5, 100)            8424100   \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 5, 16)             4816      \n",
      "_________________________________________________________________\n",
      "max_pooling1d_1 (MaxPooling1 (None, 3, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 3, 8)              392       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_2 (MaxPooling1 (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, 2, 8)              200       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_3 (MaxPooling1 (None, 1, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 1, 8)              200       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_1 (UpSampling1 (None, 2, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 2, 8)              200       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_2 (UpSampling1 (None, 4, 8)              0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 2, 16)             400       \n",
      "_________________________________________________________________\n",
      "up_sampling1d_3 (UpSampling1 (None, 4, 16)             0         \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 4, 9)              441       \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 36)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 5)                 185       \n",
      "=================================================================\n",
      "Total params: 8,430,934\n",
      "Trainable params: 6,834\n",
      "Non-trainable params: 8,424,100\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "## load our established model\n",
    "autoencoder =  load_model('autoencoder.h5')\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 736556 samples, validate on 147311 samples\n",
      "Epoch 1/10\n",
      "736556/736556 [==============================] - 61s - loss: 0.2929 - val_loss: 0.2849\n",
      "Epoch 2/10\n",
      "736556/736556 [==============================] - 64s - loss: 0.2780 - val_loss: 0.2812\n",
      "Epoch 3/10\n",
      "736556/736556 [==============================] - 54s - loss: 0.2725 - val_loss: 0.2697\n",
      "Epoch 4/10\n",
      "736556/736556 [==============================] - 54s - loss: 0.2693 - val_loss: 0.2636\n",
      "Epoch 5/10\n",
      "736556/736556 [==============================] - 59s - loss: 0.2665 - val_loss: 0.2771\n",
      "Epoch 6/10\n",
      "736556/736556 [==============================] - 63s - loss: 0.2642 - val_loss: 0.2682\n",
      "Epoch 7/10\n",
      "736556/736556 [==============================] - 58s - loss: 0.2622 - val_loss: 0.2579\n",
      "Epoch 8/10\n",
      "736556/736556 [==============================] - 54s - loss: 0.2596 - val_loss: 0.2621\n",
      "Epoch 9/10\n",
      "736556/736556 [==============================] - 53s - loss: 0.2562 - val_loss: 0.2531\n",
      "Epoch 10/10\n",
      "736556/736556 [==============================] - 60s - loss: 0.2528 - val_loss: 0.2529\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1243e9978>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run over epochs and specify the validation split\n",
    "autoencoder.fit(x_train, y_train, validation_data=(x_val,y_val),\n",
    "          epochs=10,batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get predicton probbilities for our model\n",
    "y_predicted_arr = autoencoder.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "184139"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_predicted_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## get the predicted classes\n",
    "y_predicted = []\n",
    "for i in y_predicted_arr:\n",
    "    y_predicted.append(np.where(np.max(i) == i)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## get the original labels\n",
    "y_test_labels = []\n",
    "for i in y_test:\n",
    "    y_test_labels.append(np.where(i==1)[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91162654299197887"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## recall score of the model using scikit-learn (true positive/ true positive + false negative)\n",
    "recall_score(y_test_labels, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91255144069035776"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## precision score of the model using scikit-learn (true positive/ true positive + false positive)\n",
    "precision_score(y_test_labels, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91186839680637077"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## f1-score of the model using scikit-learn (2 * (precision * recall) / (precision + recall))\n",
    "f1_score(y_test_labels, y_predicted, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>preparation(0)</th>\n",
       "      <th>ingredients(1)</th>\n",
       "      <th>nutrient(2)</th>\n",
       "      <th>reviews(3)</th>\n",
       "      <th>title(4)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>29417</td>\n",
       "      <td>862</td>\n",
       "      <td>36</td>\n",
       "      <td>3460</td>\n",
       "      <td>1049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1687</td>\n",
       "      <td>32574</td>\n",
       "      <td>2</td>\n",
       "      <td>794</td>\n",
       "      <td>1247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36903</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3009</td>\n",
       "      <td>349</td>\n",
       "      <td>1</td>\n",
       "      <td>34811</td>\n",
       "      <td>920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>977</td>\n",
       "      <td>449</td>\n",
       "      <td>5</td>\n",
       "      <td>1407</td>\n",
       "      <td>34161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   preparation(0)  ingredients(1)  nutrient(2)  reviews(3)  title(4)\n",
       "0           29417             862           36        3460      1049\n",
       "1            1687           32574            2         794      1247\n",
       "2               0               0        36903           0        19\n",
       "3            3009             349            1       34811       920\n",
       "4             977             449            5        1407     34161"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Confusion matrix that gives us sentences that were predicted correctly and that weren't ( ex : 0th row and 1st column indicates preparation misclassified as an ingredient)\n",
    "pd.DataFrame(metrics.confusion_matrix(y_test_labels,y_predicted),columns = ['preparation(0)','ingredients(1)','nutrient(2)','reviews(3)','title(4)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## save our model\n",
    "autoencoder.save('autoencoder.h5')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [py34]",
   "language": "python",
   "name": "Python [py34]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
